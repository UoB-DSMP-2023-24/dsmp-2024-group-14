{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25f6a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset containing sequence features\n",
    "data = pd.read_csv(\"alpha_p.csv\") \n",
    "\n",
    "# 假设 `data` 是已加载的pandas DataFrame，并且包含了上述的列\n",
    "\n",
    "class_counts = data['antigen.epitope'].value_counts()\n",
    "\n",
    "# Find classes that have only one instance\n",
    "single_classes = class_counts[class_counts == 1].index\n",
    "\n",
    "\n",
    "# Remove rows where 'antigen.epitope' belongs to classes with only one instance\n",
    "data_filtered = data[~data['antigen.epitope'].isin(single_classes)]\n",
    "\n",
    "# 首先，根据`cdr3_a_aa`、`v_a_gene`和`j_a_gene`来计算距离矩阵\n",
    "# 计算距离矩阵的具体代码将根据所选算法和数据类型有所不同\n",
    "\n",
    "# 定义特征列和目标列\n",
    "feature_columns = ['cdr3_a_aa', 'v_a_gene', 'j_a_gene']\n",
    "target_column = 'antigen.epitope'\n",
    "\n",
    "# 提取特征和目标\n",
    "X = data_filtered[feature_columns]  # 或是距离矩阵，取决于您的模型需求\n",
    "y = data_filtered[target_column]\n",
    "len(y)\n",
    "len(X)\n",
    "# 分层划分测试集和训练集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 以下是计算距离矩阵和模型训练的代码，这需要进一步的信息\n",
    "X_train.to_csv('human_alpha_train.csv')\n",
    "X_test.to_csv('human_alpha_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d5923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LGYGFVNYI', 'FPQSAPHGVVF', 'GLLDEDFYA', 'HQNPVTGLLL', 'RVSTLRVSL',\n",
       "       'SYMIMEIE', 'TLATHGLAAV', 'LLFNKVTLA', 'MPYGYVLNEF', 'KQIYKTPPI',\n",
       "       ...\n",
       "       'FSWGAEGQRPGF', 'MDFARVHFISALHGSG', 'ENPVVHFFKNIVTP', 'LQPLALEGSLQKRG',\n",
       "       'QPLALEGSLQKRG', 'SMGVTYEM', 'YMGVSYEM', 'YMGVVYEM', 'KMGVTYEM',\n",
       "       'RPPIFIRRL'],\n",
       "      dtype='object', length=184)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59885bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/tcrdist/repertoire.py:159: UserWarning: cell_df needs a counts column to track clonal number of frequency\n",
      "\n",
      "  self._validate_cell_df()\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/tcrdist/repertoire.py:791: UserWarning: No 'count' column provided; count column set to 1\n",
      "  warnings.warn(\"No 'count' column provided; count column set to 1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0, 138,   0, ...,  90,  78, 159],\n",
       "       [138,   0, 138, ..., 129, 141, 141],\n",
       "       [  0, 138,   0, ...,  90,  78, 159],\n",
       "       ...,\n",
       "       [ 90, 129,  90, ...,   0,  42, 138],\n",
       "       [ 78, 141,  78, ...,  42,   0, 144],\n",
       "       [159, 141, 159, ..., 138, 144,   0]], dtype=int16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tcrdist.repertoire import TCRrep\n",
    "#创造‘TCRrep’类\n",
    "#alpha chain\n",
    "data_alpha = pd.read_csv(\"human_alpha_train.csv\")\n",
    "tr_alpha = TCRrep(cell_df=data_alpha, \n",
    "                  organism='human', \n",
    "                  chains=['alpha'], \n",
    "                  db_file='alphabeta_gammadelta_db.tsv')\n",
    "tr_alpha.compute_distances()\n",
    "\n",
    "distance_matrix = tr_alpha.pw_alpha\n",
    "#np.save('alpha_distance_people_matrix.npy', alpha_distance_matrix)\n",
    "tr_alpha.pw_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74721400",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2223 is out of bounds for axis 0 with size 2054",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m indices_train, indices_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(indices, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 使用训练集的索引创建训练用的距离矩阵\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m distance_matrix_train \u001b[38;5;241m=\u001b[39m distance_matrix[np\u001b[38;5;241m.\u001b[39mix_(indices_train, indices_train)]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 使用训练集和测试集的索引创建预测用的距离矩阵\u001b[39;00m\n\u001b[1;32m     10\u001b[0m distance_matrix_test \u001b[38;5;241m=\u001b[39m distance_matrix[np\u001b[38;5;241m.\u001b[39mix_(indices_test, indices_train)]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2223 is out of bounds for axis 0 with size 2054"
     ]
    }
   ],
   "source": [
    "# 划分数据集\n",
    "# 注意：对于K-NN，我们不需要转换为特征向量，但我们需要索引来跟踪训练集和测试集\n",
    "indices = range(len(y))\n",
    "indices_train, indices_test, y_train, y_test = train_test_split(indices, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 使用训练集的索引创建训练用的距离矩阵\n",
    "distance_matrix_train = distance_matrix[np.ix_(indices_train, indices_train)]\n",
    "\n",
    "# 使用训练集和测试集的索引创建预测用的距离矩阵\n",
    "distance_matrix_test = distance_matrix[np.ix_(indices_test, indices_train)]\n",
    "\n",
    "# 训练K-NN模型，假设k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n",
    "knn.fit(distance_matrix_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = knn.predict(distance_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a2a528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      0.50      0.50         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.50      0.67      0.57         3\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          12       1.00      1.00      1.00         1\n",
      "          15       0.33      1.00      0.50         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.17      0.50      0.25         2\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          27       0.10      0.25      0.14         4\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.25      1.00      0.40         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.22      1.00      0.36         2\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "          51       0.08      0.33      0.13         3\n",
      "          52       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         2\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         0\n",
      "          66       0.67      0.57      0.62         7\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         1\n",
      "          74       0.43      0.65      0.52        23\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         1\n",
      "          86       0.56      0.76      0.65        59\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.52      0.73      0.61        15\n",
      "          89       0.20      0.25      0.22         4\n",
      "          90       0.00      0.00      0.00         1\n",
      "          93       0.25      0.17      0.20         6\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         3\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         2\n",
      "         104       0.50      0.50      0.50         2\n",
      "         105       0.30      0.75      0.43         4\n",
      "         108       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         0\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         117       0.43      1.00      0.60         3\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.33      0.17      0.22         6\n",
      "         122       0.00      0.00      0.00         4\n",
      "         123       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         1\n",
      "         129       0.00      0.00      0.00         1\n",
      "         131       0.42      0.33      0.37        15\n",
      "         133       0.00      0.00      0.00         1\n",
      "         135       0.50      0.50      0.50         2\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         3\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         3\n",
      "         158       1.00      0.40      0.57         5\n",
      "         159       0.25      0.33      0.29         3\n",
      "         160       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         1\n",
      "         170       0.00      0.00      0.00         1\n",
      "         171       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       0.00      0.00      0.00         1\n",
      "         181       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         0\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         6\n",
      "         197       0.68      0.91      0.78        46\n",
      "         198       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         3\n",
      "         201       0.52      0.46      0.49        91\n",
      "         204       0.00      0.00      0.00         1\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         2\n",
      "         210       0.00      0.00      0.00         4\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         7\n",
      "         213       0.00      0.00      0.00         2\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       1.00      0.33      0.50         3\n",
      "         216       0.00      0.00      0.00         2\n",
      "         218       0.00      0.00      0.00         0\n",
      "         219       0.00      0.00      0.00         1\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       0.60      0.60      0.60         5\n",
      "         223       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       0.00      0.00      0.00        10\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         2\n",
      "         240       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         5\n",
      "         245       1.00      1.00      1.00         1\n",
      "         248       0.00      0.00      0.00         4\n",
      "         249       0.00      0.00      0.00         3\n",
      "         251       0.00      0.00      0.00         1\n",
      "         258       0.33      0.25      0.29         4\n",
      "         260       0.00      0.00      0.00         1\n",
      "         266       0.00      0.00      0.00         2\n",
      "         269       0.00      0.00      0.00         0\n",
      "         271       0.00      0.00      0.00         2\n",
      "         272       0.00      0.00      0.00         1\n",
      "         273       0.00      0.00      0.00         1\n",
      "         274       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         1\n",
      "         279       0.00      0.00      0.00         4\n",
      "         280       0.00      0.00      0.00         2\n",
      "         281       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00         1\n",
      "         284       0.00      0.00      0.00         2\n",
      "         285       0.67      0.29      0.40         7\n",
      "         287       0.71      0.89      0.79        19\n",
      "         292       0.00      0.00      0.00         3\n",
      "         293       0.00      0.00      0.00         1\n",
      "         297       0.00      0.00      0.00         1\n",
      "         298       0.00      0.00      0.00         3\n",
      "         299       0.00      0.00      0.00         2\n",
      "         306       0.00      0.00      0.00         1\n",
      "         308       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         1\n",
      "         312       0.00      0.00      0.00         1\n",
      "         313       0.00      0.00      0.00         2\n",
      "         320       0.00      0.00      0.00         2\n",
      "         323       0.00      0.00      0.00         1\n",
      "         326       0.00      0.00      0.00         1\n",
      "         327       0.73      0.44      0.55        18\n",
      "         328       0.00      0.00      0.00         1\n",
      "         330       0.00      0.00      0.00         1\n",
      "         332       0.00      0.00      0.00         1\n",
      "         336       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40       551\n",
      "   macro avg       0.09      0.11      0.09       551\n",
      "weighted avg       0.36      0.40      0.37       551\n",
      "\n",
      "Accuracy: 0.4029038112522686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 假设 data 是加载的 DataFrame，包含 'cdr3_a_aa', 'v_a_gene', 'j_a_gene' 和 'antigen.epitope' 列\n",
    "\n",
    "# 首先，我们需要将分类数据转换为数值数据，这里使用 LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 对 'cdr3_a_aa', 'v_a_gene', 'j_a_gene' 进行编码\n",
    "data['cdr3_a_aa_encoded'] = le.fit_transform(data['cdr3_a_aa'])\n",
    "data['v_a_gene_encoded'] = le.fit_transform(data['v_a_gene'])\n",
    "data['j_a_gene_encoded'] = le.fit_transform(data['j_a_gene'])\n",
    "\n",
    "# 提取特征和目标变量\n",
    "X = data[['cdr3_a_aa_encoded', 'v_a_gene_encoded', 'j_a_gene_encoded']]\n",
    "y = le.fit_transform(data['antigen.epitope'])  # 对目标变量也进行编码\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用 K-近邻算法创建模型实例\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# 训练模型\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 打印分类报告和准确率\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "852e282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         6\n",
      "           8       1.00      1.00      1.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.20      0.50      0.29         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.25      1.00      0.40         1\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.33      0.50      0.40         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.50      0.29      0.36         7\n",
      "          28       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          34       0.40      1.00      0.57         2\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.42      0.74      0.54        23\n",
      "          40       0.50      1.00      0.67         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.64      0.70      0.67        70\n",
      "          47       0.59      0.67      0.62        15\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.60      0.43      0.50         7\n",
      "          58       0.25      1.00      0.40         1\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.67      1.00      0.80         2\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.50      0.50      0.50         6\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.33      0.33      0.33         9\n",
      "          70       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         3\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.50      0.25      0.33         4\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.33      0.50      0.40         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.50      1.00      0.67         1\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         3\n",
      "          94       0.69      0.81      0.75        54\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.45      0.44      0.45       106\n",
      "          98       0.00      0.00      0.00         1\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         3\n",
      "         108       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.33      0.50      0.40         4\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         2\n",
      "         115       0.00      0.00      0.00         6\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.50      1.00      0.67         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         3\n",
      "         120       0.00      0.00      0.00         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         3\n",
      "         127       0.40      0.40      0.40         5\n",
      "         129       1.00      0.25      0.40         4\n",
      "         130       0.40      1.00      0.57         2\n",
      "         133       0.00      0.00      0.00         7\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         3\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       0.25      1.00      0.40         1\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.62      0.89      0.73        18\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       1.00      1.00      1.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.67      0.32      0.43        25\n",
      "\n",
      "    accuracy                           0.45       514\n",
      "   macro avg       0.14      0.17      0.14       514\n",
      "weighted avg       0.42      0.45      0.42       514\n",
      "\n",
      "Accuracy: 0.45136186770428016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 假设 data 是加载的 DataFrame，包含 'cdr3_a_aa', 'v_a_gene', 'j_a_gene' 和 'antigen.epitope' 列\n",
    "\n",
    "# 首先，我们需要将分类数据转换为数值数据，这里使用 LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 对 'cdr3_a_aa', 'v_a_gene', 'j_a_gene' 进行编码\n",
    "data_filtered['cdr3_a_aa_encoded'] = le.fit_transform(data_filtered['cdr3_a_aa'])\n",
    "data_filtered['v_a_gene_encoded'] = le.fit_transform(data_filtered['v_a_gene'])\n",
    "data_filtered['j_a_gene_encoded'] = le.fit_transform(data_filtered['j_a_gene'])\n",
    "\n",
    "# 提取特征和目标变量\n",
    "X = data_filtered[['cdr3_a_aa_encoded', 'v_a_gene_encoded', 'j_a_gene_encoded']]\n",
    "y = le.fit_transform(data_filtered['antigen.epitope'])  # 对目标变量也进行编码\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用 K-近邻算法创建模型实例\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 训练模型\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 打印分类报告和准确率\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dba81539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.33      1.00      0.50         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         6\n",
      "           8       1.00      1.00      1.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.33      0.50      0.40         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.33      0.50      0.40         2\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.33      1.00      0.50         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.38      0.71      0.50         7\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         1\n",
      "          34       0.67      1.00      0.80         2\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.40      0.83      0.54        23\n",
      "          40       0.25      1.00      0.40         1\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.57      0.79      0.66        70\n",
      "          47       0.50      0.87      0.63        15\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.60      0.43      0.50         7\n",
      "          58       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.75      1.00      0.86         6\n",
      "          66       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.33      0.44      0.38         9\n",
      "          70       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         3\n",
      "          77       0.50      1.00      0.67         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       1.00      0.67      0.80         3\n",
      "          80       0.50      0.25      0.33         4\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.50      0.50      0.50         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         3\n",
      "          94       0.65      0.78      0.71        54\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.54      0.45      0.49       106\n",
      "          98       0.00      0.00      0.00         1\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         3\n",
      "         108       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       1.00      0.25      0.40         4\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         2\n",
      "         115       0.00      0.00      0.00         6\n",
      "         117       0.50      1.00      0.67         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         3\n",
      "         120       0.67      1.00      0.80         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         3\n",
      "         127       0.67      0.40      0.50         5\n",
      "         129       0.00      0.00      0.00         4\n",
      "         130       1.00      1.00      1.00         2\n",
      "         133       0.00      0.00      0.00         7\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       1.00      0.67      0.80         3\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       1.00      1.00      1.00         1\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.78      1.00      0.88        18\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.64      0.36      0.46        25\n",
      "\n",
      "    accuracy                           0.50       514\n",
      "   macro avg       0.17      0.20      0.17       514\n",
      "weighted avg       0.44      0.50      0.45       514\n",
      "\n",
      "Accuracy: 0.4961089494163424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 创建 OneHotEncoder，对序列和基因名称进行独热编码\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('cdr3_a_aa_ohe', OneHotEncoder(), ['cdr3_a_aa']),\n",
    "    ('v_a_gene_ohe', OneHotEncoder(), ['v_a_gene']),\n",
    "    ('j_a_gene_ohe', OneHotEncoder(), ['j_a_gene'])\n",
    "], remainder='drop')  # drop 表示除了指定的列以外的其他列将被丢弃\n",
    "\n",
    "# 对特征进行独热编码转换\n",
    "X_encoded = column_transformer.fit_transform(data_filtered)\n",
    "\n",
    "# 标签也需要转换为数值型\n",
    "y_encoded = LabelEncoder().fit_transform(data_filtered['antigen.epitope'])\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建并训练模型，这里我们仍然使用 KNN，但你也可以尝试其他模型\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# 输出模型表现\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ad1592",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['CAVSGQGDDKIIF', 'CALMSARLMF', 'CWSPFGNEKLTF', 'CAGASPGGYGGSQGNLIF', 'CALSAPYSGGGADGLTF', 'CALSGANAGNMLTF', 'CAEGEAGTALIF', 'CAMSGYTNAGKSTF', 'CALKISGSGYALNF', 'CAVQAGNNNDMRF', 'CIALNARLMF', 'CAVQAGGNNRLAF', 'CALVYSGGYQKVTF', 'CAALANQAGTALIF', 'CAMREVNDYKLSF', 'CAGLNQGAQKLVF', 'CVVVRMDSSYKLIF', 'CAASSPSGGYQKVTF', 'CAVTGGGSQGNLIF', 'CLVGGAYTGGFKTIF', 'CALDDRGSTLGRLYF', 'CALRMIGGGSNYKLTF', 'CAVLPHGNNRLAF', 'CAVRGPMNTGFQKLVF', 'CIVRAPPDSWGKLQF', 'CAASLSGGGADGLTF', 'CAASLNTGKLIF', 'CALSENFIQGAQKLVF', 'CAVQAAREYNFNKFYF', 'CAGRTFDKIIF', 'CATEGDSGYSTLTF', 'CAEENAGNMLTF', 'CAVRDPLYNFNKFYF', 'CAEDAASTLTF', 'CAYRSVQGAQKLVF', 'CAASVLYGQNFVF', 'CVVRAGKLIF', 'CAASINSGNTPLVF', 'CVVNNAGNMLTF', 'CLVGGDNQGGKLIF', 'CLVGAGNMLTF', 'CALSNDYKLSF', 'CASGGGADGLTF', 'CAGNTGTASKLTF', 'CIVHTNSGGSNYKLTF', 'CAVDNARLMF', 'CAVKGSQGNLIF', 'CAGQLSGGSNYKLTF', 'CAASAGGNNRLAF', 'CAMSVNAGGTSYGKLTF', 'CASDDARLMF', 'CAESGGNNNDMRF', 'CAFFPYGQNFVF', 'CAVWDTGKLIF', 'CALSDRDGGTSYGKLTF', 'CALSEHTTDSWGKFQF', 'CATDGDSGAGSYQLTF', 'CAASAANFANDKLTF', 'CAAVHDYKLSF', 'CAFTNYNQGGKLIF', 'CAYRSGYMEYGNKLVF', 'CATEARMDSSYKLIF', 'CAFGRGNNDMRF', 'CAESEGKLIF', 'CAVGSNSGYALNF', 'CALSGSSVGAAGNKLTF', 'CAYRSSNFNEKLTF', 'CAVSSAGGFKTIF', 'CAVAHSGGYQKVTF', 'CAFMKHEDSGAGSYQLTF', 'CAMREDSIGNTPLVF', 'CALDNAGHMLTF', 'CAFMNHTGTASKLTF', 'CAVGEDSSYKLIF', 'CAEDNYGQNFVF', 'CAGRHGGTSYGKLTF', 'CAGYNSGGSNYKLTF', 'CAGQPGAGGSQGNLIF', 'CALQGWVRGADGLTF', 'CAVRDVNTGFQKLVF', 'CAGAGNTGKLIF', 'CAYNAGNMLTF', 'CAVNPGNQFYF', 'CAVGTAWRSGGGADGLTF', 'CAVRDYGQNFVF', 'CALSEGYNFNKFYF', 'CAVDISNAGNMLTF', 'CAYRSAFKLTF', 'CAVNPIGGYNKLIF', 'CAGHLFKAAGNKLTF', 'CAYYGGNQFYF', 'CPTLGGSNYKLTF', 'CALILNQAGTALIF', 'CAFTAAGNKLTF', 'CAVDGSQGNLIF', 'CAVSGYGGSQGNLIF', 'CAYRSAGGGTSYGKLTF', 'CAASHIQGAQKLVF', 'CAVGNAITSSSDKLIF', 'CAGPTTSGTYKYIF', 'CAAREDSSYKLIF', 'CAASLNSGGYQKVTF', 'CLKAGGFKTIF', 'CARPAAERDDKIIF', 'CVVNSWAGNQFYF', 'CAVGDGNNRLAF', 'CATYLTGNQFYF', 'CASISNTGNQFYF', 'CGADWKTSYDKVIF', 'CATDEAGRRALTF', 'CAYPYNNNDMRF', 'CAVSEISGTYKYIF', 'CILRDVSGGGSNYKLTF', 'CALSEAGYGGATNKLIF', 'CASKAAGTKLTF', 'CAGSYGGSQGNLIF', 'CAFETGNQFYF', 'CAFISTQGGSEKLVF', 'CAGLGNFGNEKLTF', 'CAVLQRRSGGSNYKLTF', 'CASTAGPNFGNEKLTF', 'CAWRGGGGADGLTF', 'CAAAASGGSYIPTF', 'CAETPTNDYKLSF', 'CAASARGNQGGKLIF', 'CAASAGSYNSDKLIF', 'CAFSGGSNYKLTF', 'CAMREGRYSSASKIIF', 'CALIQGAQKLVF', 'CLVGEAAGNKLTF', 'CALSEATSGTYKYIF', 'CAVFMDSNYQLIW', 'CAASKAAGNKLTF', 'CAEMNSGYSTLTF', 'CAVDTGTASKLTF', 'CAVRHTNAGKSTF', 'CAFTELNSGGSNYKLTF', 'CAGKSLFGTNAGKSTF', 'CAVYPGGSQGNLIF', 'CALEAGNKLTF', 'CAMNTGNQFYF', 'CAVSESRNRDDKIIF', 'CATDALGNGNEKLTF', 'CAVATGAAGNKLTF', 'CAVQGSQGNLIF', 'CAVDANNDMRF', 'CAVSESGGSYIPTF', 'CLVPSEQAGTALIF', 'CAVEPMEYGNKLVF', 'CAVSEGGATNKLIF', 'CAVTDDKIIF', 'CAVGGLSGANSKLTF', 'CAVRSDQAGTALIF', 'CAVPWGGNTGKLIF', 'CILRSSSGGGSNYKLTF', 'CGADFLMNRDDKIIF', 'CAAFDDKIIF', 'CARDAGNMLTF', 'CALFTGGGNKLTF', 'CASSGGNTPLVF', 'CAYVQDDKIIF', 'CAYIIIQGAQKLVF', 'CAVNALLGNQFYF', 'CVVNGNNNDMRF', 'CLVGDIGAAGNKLTF', 'CAAPNSGGSNYKLTF', 'CAESGGSNYKLTF', 'CAVQFMDSNYQLIW', 'CAVIKGYSTLTF', 'CAATSGTYKYIF', 'CAIQTGANNLFF', 'CAAQRANRDDKIIF', 'CALNKTHNNLTF', 'CAYRSHYTSGTYKYIF', 'CAVANQAGTALIF', 'CAVDVNDYKLSF', 'CALRSGYALNF', 'CAGQASQGNLIF', 'CALPREYGNKLVF', 'CAGQLQKAACNKLIF', 'CAVHTGARLMF', 'CAVDDLYSNYQLIW', 'CAVRAYGQNFVF', 'CAVEGAGSYQLTF', 'CAFCGGTSYGKLTF', 'CALSESGANSKLTF', 'CAETYTGNQFYF', 'CAVILRSNDYKLSF', 'CALSGGYQKVTF', 'CAENSNTGNQFYF', 'CVVRGMDSSYKLIF', 'CAAEAGNHRGSTLGRLYF', 'CAVYTGGFKTIF', 'CSKTSYDKVIF', 'CVAASYNTDKLIF', 'CALRGYGQNFVF', 'CILRDDNDMRF', 'CALDTARLMF', 'CAVERGGGNKLTF', 'CAFKGAGNKLTF', 'CAGGYGGSQGNLIF', 'CLVGDGGSFSGGYNKLIF', 'CALSEVQLMDSNYQLIW', 'CLLMEYGNKLVF', 'CAMRDPHLWSGATNKLIF', 'CAYREGAQKLVF', 'CVGGGGTSGGGADGLTF', 'CAESKRDGGATNKLIF', 'CAVRDNSITGGFKTIF', 'CAPRNAGGTSYGKLTF', 'CAVDSSASKIIF', 'CAVSDLEPNSSASKIIF', 'CAFEDSGGSNYKLTF', 'CAHNTGNQFYF', 'CVVIEGNKLVF', 'CAENGGGSTLGRLYF', 'CAERIQTGANNLFF', 'CAVKSWSGPGWGNQAGTALIF', 'CAGLKAAGNKLTF', 'CPFQTGANNLFF', 'CLVAGAGGYNKLIF', 'CAVQTLGNAGNMLTF', 'CAVRDINARLMF', 'CAGMDSNYQLIW', 'CAARGGADGLTF', 'CALSLYSGAGSYQLTF', 'CAVIPDFGNEKLTF', 'CALSENKLSF', 'CAITGGFKTIF', 'CVVNTGGSYIPTF', 'CAVRPGYSSASKIIF', 'CIVKTNSGGSNYKLTF', 'CSPQGGSEKLVF', 'CAEDQNARLMF', 'CAEKGGTALIF', 'CATDVAGRRALTF', 'CAVGGNDWNTDKLIF', 'CAPSAGTYNTDKLIF', 'CAYGANNLFF', 'CLVGDNDYKLSF', 'CAVTHRFHTASKLTF', 'CAVPSGSARQLTF', 'CAYRDDKIIF', 'CAGPYTGANSKLTF', 'CATDLKTSYDKVIF', 'CALSEFRGNTPLVF', 'CASGLPDTPLVF', 'CAPPEGGATNKLIF', 'CAVTDSWGKLQF', 'CAVEDTNSGYALNF', 'CADLNARLMF', 'CAVTAGGGNKLTF', 'CVGNSYGQNFVF', 'CACLTGTASKLTF', 'CAVRDPGNTDKLIF', 'CAVISGGGADGLTF'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m model_pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 在测试集上进行预测\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# 输出模型表现\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    505\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:816\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 816\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(\n\u001b[1;32m    817\u001b[0m     X,\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    819\u001b[0m     _transform_one,\n\u001b[1;32m    820\u001b[0m     fitted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    821\u001b[0m     column_as_strings\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    664\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[1;32m    666\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m )\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[1;32m    671\u001b[0m         delayed(func)(\n\u001b[1;32m    672\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m    673\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    674\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    675\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[1;32m    676\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    677\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:933\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m--> 933\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:1016\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1015\u001b[0m }\n\u001b[0;32m-> 1016\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(\n\u001b[1;32m   1017\u001b[0m     X,\n\u001b[1;32m   1018\u001b[0m     handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown,\n\u001b[1;32m   1019\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1020\u001b[0m     warn_on_unknown\u001b[38;5;241m=\u001b[39mwarn_on_unknown,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1023\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:199\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    195\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[1;32m    198\u001b[0m     )\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['CAVSGQGDDKIIF', 'CALMSARLMF', 'CWSPFGNEKLTF', 'CAGASPGGYGGSQGNLIF', 'CALSAPYSGGGADGLTF', 'CALSGANAGNMLTF', 'CAEGEAGTALIF', 'CAMSGYTNAGKSTF', 'CALKISGSGYALNF', 'CAVQAGNNNDMRF', 'CIALNARLMF', 'CAVQAGGNNRLAF', 'CALVYSGGYQKVTF', 'CAALANQAGTALIF', 'CAMREVNDYKLSF', 'CAGLNQGAQKLVF', 'CVVVRMDSSYKLIF', 'CAASSPSGGYQKVTF', 'CAVTGGGSQGNLIF', 'CLVGGAYTGGFKTIF', 'CALDDRGSTLGRLYF', 'CALRMIGGGSNYKLTF', 'CAVLPHGNNRLAF', 'CAVRGPMNTGFQKLVF', 'CIVRAPPDSWGKLQF', 'CAASLSGGGADGLTF', 'CAASLNTGKLIF', 'CALSENFIQGAQKLVF', 'CAVQAAREYNFNKFYF', 'CAGRTFDKIIF', 'CATEGDSGYSTLTF', 'CAEENAGNMLTF', 'CAVRDPLYNFNKFYF', 'CAEDAASTLTF', 'CAYRSVQGAQKLVF', 'CAASVLYGQNFVF', 'CVVRAGKLIF', 'CAASINSGNTPLVF', 'CVVNNAGNMLTF', 'CLVGGDNQGGKLIF', 'CLVGAGNMLTF', 'CALSNDYKLSF', 'CASGGGADGLTF', 'CAGNTGTASKLTF', 'CIVHTNSGGSNYKLTF', 'CAVDNARLMF', 'CAVKGSQGNLIF', 'CAGQLSGGSNYKLTF', 'CAASAGGNNRLAF', 'CAMSVNAGGTSYGKLTF', 'CASDDARLMF', 'CAESGGNNNDMRF', 'CAFFPYGQNFVF', 'CAVWDTGKLIF', 'CALSDRDGGTSYGKLTF', 'CALSEHTTDSWGKFQF', 'CATDGDSGAGSYQLTF', 'CAASAANFANDKLTF', 'CAAVHDYKLSF', 'CAFTNYNQGGKLIF', 'CAYRSGYMEYGNKLVF', 'CATEARMDSSYKLIF', 'CAFGRGNNDMRF', 'CAESEGKLIF', 'CAVGSNSGYALNF', 'CALSGSSVGAAGNKLTF', 'CAYRSSNFNEKLTF', 'CAVSSAGGFKTIF', 'CAVAHSGGYQKVTF', 'CAFMKHEDSGAGSYQLTF', 'CAMREDSIGNTPLVF', 'CALDNAGHMLTF', 'CAFMNHTGTASKLTF', 'CAVGEDSSYKLIF', 'CAEDNYGQNFVF', 'CAGRHGGTSYGKLTF', 'CAGYNSGGSNYKLTF', 'CAGQPGAGGSQGNLIF', 'CALQGWVRGADGLTF', 'CAVRDVNTGFQKLVF', 'CAGAGNTGKLIF', 'CAYNAGNMLTF', 'CAVNPGNQFYF', 'CAVGTAWRSGGGADGLTF', 'CAVRDYGQNFVF', 'CALSEGYNFNKFYF', 'CAVDISNAGNMLTF', 'CAYRSAFKLTF', 'CAVNPIGGYNKLIF', 'CAGHLFKAAGNKLTF', 'CAYYGGNQFYF', 'CPTLGGSNYKLTF', 'CALILNQAGTALIF', 'CAFTAAGNKLTF', 'CAVDGSQGNLIF', 'CAVSGYGGSQGNLIF', 'CAYRSAGGGTSYGKLTF', 'CAASHIQGAQKLVF', 'CAVGNAITSSSDKLIF', 'CAGPTTSGTYKYIF', 'CAAREDSSYKLIF', 'CAASLNSGGYQKVTF', 'CLKAGGFKTIF', 'CARPAAERDDKIIF', 'CVVNSWAGNQFYF', 'CAVGDGNNRLAF', 'CATYLTGNQFYF', 'CASISNTGNQFYF', 'CGADWKTSYDKVIF', 'CATDEAGRRALTF', 'CAYPYNNNDMRF', 'CAVSEISGTYKYIF', 'CILRDVSGGGSNYKLTF', 'CALSEAGYGGATNKLIF', 'CASKAAGTKLTF', 'CAGSYGGSQGNLIF', 'CAFETGNQFYF', 'CAFISTQGGSEKLVF', 'CAGLGNFGNEKLTF', 'CAVLQRRSGGSNYKLTF', 'CASTAGPNFGNEKLTF', 'CAWRGGGGADGLTF', 'CAAAASGGSYIPTF', 'CAETPTNDYKLSF', 'CAASARGNQGGKLIF', 'CAASAGSYNSDKLIF', 'CAFSGGSNYKLTF', 'CAMREGRYSSASKIIF', 'CALIQGAQKLVF', 'CLVGEAAGNKLTF', 'CALSEATSGTYKYIF', 'CAVFMDSNYQLIW', 'CAASKAAGNKLTF', 'CAEMNSGYSTLTF', 'CAVDTGTASKLTF', 'CAVRHTNAGKSTF', 'CAFTELNSGGSNYKLTF', 'CAGKSLFGTNAGKSTF', 'CAVYPGGSQGNLIF', 'CALEAGNKLTF', 'CAMNTGNQFYF', 'CAVSESRNRDDKIIF', 'CATDALGNGNEKLTF', 'CAVATGAAGNKLTF', 'CAVQGSQGNLIF', 'CAVDANNDMRF', 'CAVSESGGSYIPTF', 'CLVPSEQAGTALIF', 'CAVEPMEYGNKLVF', 'CAVSEGGATNKLIF', 'CAVTDDKIIF', 'CAVGGLSGANSKLTF', 'CAVRSDQAGTALIF', 'CAVPWGGNTGKLIF', 'CILRSSSGGGSNYKLTF', 'CGADFLMNRDDKIIF', 'CAAFDDKIIF', 'CARDAGNMLTF', 'CALFTGGGNKLTF', 'CASSGGNTPLVF', 'CAYVQDDKIIF', 'CAYIIIQGAQKLVF', 'CAVNALLGNQFYF', 'CVVNGNNNDMRF', 'CLVGDIGAAGNKLTF', 'CAAPNSGGSNYKLTF', 'CAESGGSNYKLTF', 'CAVQFMDSNYQLIW', 'CAVIKGYSTLTF', 'CAATSGTYKYIF', 'CAIQTGANNLFF', 'CAAQRANRDDKIIF', 'CALNKTHNNLTF', 'CAYRSHYTSGTYKYIF', 'CAVANQAGTALIF', 'CAVDVNDYKLSF', 'CALRSGYALNF', 'CAGQASQGNLIF', 'CALPREYGNKLVF', 'CAGQLQKAACNKLIF', 'CAVHTGARLMF', 'CAVDDLYSNYQLIW', 'CAVRAYGQNFVF', 'CAVEGAGSYQLTF', 'CAFCGGTSYGKLTF', 'CALSESGANSKLTF', 'CAETYTGNQFYF', 'CAVILRSNDYKLSF', 'CALSGGYQKVTF', 'CAENSNTGNQFYF', 'CVVRGMDSSYKLIF', 'CAAEAGNHRGSTLGRLYF', 'CAVYTGGFKTIF', 'CSKTSYDKVIF', 'CVAASYNTDKLIF', 'CALRGYGQNFVF', 'CILRDDNDMRF', 'CALDTARLMF', 'CAVERGGGNKLTF', 'CAFKGAGNKLTF', 'CAGGYGGSQGNLIF', 'CLVGDGGSFSGGYNKLIF', 'CALSEVQLMDSNYQLIW', 'CLLMEYGNKLVF', 'CAMRDPHLWSGATNKLIF', 'CAYREGAQKLVF', 'CVGGGGTSGGGADGLTF', 'CAESKRDGGATNKLIF', 'CAVRDNSITGGFKTIF', 'CAPRNAGGTSYGKLTF', 'CAVDSSASKIIF', 'CAVSDLEPNSSASKIIF', 'CAFEDSGGSNYKLTF', 'CAHNTGNQFYF', 'CVVIEGNKLVF', 'CAENGGGSTLGRLYF', 'CAERIQTGANNLFF', 'CAVKSWSGPGWGNQAGTALIF', 'CAGLKAAGNKLTF', 'CPFQTGANNLFF', 'CLVAGAGGYNKLIF', 'CAVQTLGNAGNMLTF', 'CAVRDINARLMF', 'CAGMDSNYQLIW', 'CAARGGADGLTF', 'CALSLYSGAGSYQLTF', 'CAVIPDFGNEKLTF', 'CALSENKLSF', 'CAITGGFKTIF', 'CVVNTGGSYIPTF', 'CAVRPGYSSASKIIF', 'CIVKTNSGGSNYKLTF', 'CSPQGGSEKLVF', 'CAEDQNARLMF', 'CAEKGGTALIF', 'CATDVAGRRALTF', 'CAVGGNDWNTDKLIF', 'CAPSAGTYNTDKLIF', 'CAYGANNLFF', 'CLVGDNDYKLSF', 'CAVTHRFHTASKLTF', 'CAVPSGSARQLTF', 'CAYRDDKIIF', 'CAGPYTGANSKLTF', 'CATDLKTSYDKVIF', 'CALSEFRGNTPLVF', 'CASGLPDTPLVF', 'CAPPEGGATNKLIF', 'CAVTDSWGKLQF', 'CAVEDTNSGYALNF', 'CADLNARLMF', 'CAVTAGGGNKLTF', 'CVGNSYGQNFVF', 'CACLTGTASKLTF', 'CAVRDPGNTDKLIF', 'CAVISGGGADGLTF'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 假设 'data' 是一个 DataFrame，包含你的三个特征列和一个目标列 'antigen.epitope'\n",
    "\n",
    "# 创建 OneHotEncoder 实例，自动忽略无法编码的数值型数据\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['cdr3_a_aa', 'v_a_gene', 'j_a_gene'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "# 创建逻辑回归模型\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 创建包含预处理和模型的管道\n",
    "model_pipeline = Pipeline([\n",
    "    ('encoder', column_transformer),\n",
    "    ('classifier', logistic_model)\n",
    "])\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['cdr3_a_aa', 'v_a_gene', 'j_a_gene']],  # 特征数据\n",
    "    data['antigen.epitope'],  # 目标数据\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# 输出模型表现\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "256fc873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1436 - loss: 4.9892 \n",
      "Epoch 2/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2883 - loss: 4.0931\n",
      "Epoch 3/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3624 - loss: 3.0302\n",
      "Epoch 4/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4373 - loss: 2.6667\n",
      "Epoch 5/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4979 - loss: 2.2825\n",
      "Epoch 6/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5460 - loss: 1.9912\n",
      "Epoch 7/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5803 - loss: 1.7862\n",
      "Epoch 8/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 1.5239\n",
      "Epoch 9/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 1.3101\n",
      "Epoch 10/10\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 1.0440\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5612 - loss: 2.2071  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2510392665863037, 0.548638105392456]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 假设 data 是你的 DataFrame，包含三个类别型特征和一个目标类别 'antigen.epitope'\n",
    "data=data_filtered\n",
    "# 将类别型特征编码为整数\n",
    "label_encoders = {}\n",
    "for column in ['cdr3_a_aa', 'v_a_gene', 'j_a_gene']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# 对目标变量进行编码\n",
    "target_encoder = LabelEncoder()\n",
    "y = target_encoder.fit_transform(data['antigen.epitope'])\n",
    "y = to_categorical(y)  # 使用 one-hot 编码目标变量\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['cdr3_a_aa', 'v_a_gene', 'j_a_gene']], y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 构建模型\n",
    "input_layers = []\n",
    "embedding_layers = []\n",
    "for column in ['cdr3_a_aa', 'v_a_gene', 'j_a_gene']:\n",
    "    num_unique_values = int(data[column].nunique())\n",
    "    embedding_dim = min(np.ceil(num_unique_values / 2), 50)\n",
    "    input_layer = Input(shape=(1,))\n",
    "    embedding_layer = Embedding(num_unique_values, int(embedding_dim), input_length=1)(input_layer)\n",
    "    embedding_layer = Flatten()(embedding_layer)\n",
    "    input_layers.append(input_layer)\n",
    "    embedding_layers.append(embedding_layer)\n",
    "\n",
    "# 合并嵌入层的输出\n",
    "concat_layer = Concatenate()(embedding_layers)\n",
    "dense_layer = Dense(64, activation='relu')(concat_layer)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(dense_layer)\n",
    "\n",
    "model = Model(inputs=input_layers, outputs=output_layer)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit([X_train[column] for column in ['cdr3_a_aa', 'v_a_gene', 'j_a_gene']], y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# 评估模型\n",
    "model.evaluate([X_test[column] for column in ['cdr3_a_aa', 'v_a_gene', 'j_a_gene']], y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faa51c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.9052 - val_accuracy: 0.8835 - val_loss: 0.7283\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.8838 - val_accuracy: 0.8981 - val_loss: 0.6575\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.5878 - val_accuracy: 0.8981 - val_loss: 0.6021\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.5442 - val_accuracy: 0.9126 - val_loss: 0.5570\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.4347 - val_accuracy: 0.9175 - val_loss: 0.5309\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.3667 - val_accuracy: 0.9223 - val_loss: 0.5054\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.3359 - val_accuracy: 0.9175 - val_loss: 0.4978\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.2566 - val_accuracy: 0.9175 - val_loss: 0.4787\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.2175 - val_accuracy: 0.9175 - val_loss: 0.4697\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9547 - loss: 0.1850 - val_accuracy: 0.9272 - val_loss: 0.4517\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5901 - loss: 2.1813 \n",
      "Test Accuracy: 0.5817120671272278\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit([X_train[column] for column in ['cdr3_a_aa', 'v_a_gene', 'j_a_gene']], y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# 评估模型，并获取测试集上的损失和准确度\n",
    "test_loss, test_accuracy = model.evaluate([X_test[column] for column in ['cdr3_a_aa', 'v_a_gene', 'j_a_gene']], y_test)\n",
    "\n",
    "# 输出测试集上的准确度\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e11c640",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Precomputed matrix must be a square matrix. Input is a 2054x2568 matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m svm_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)  \u001b[38;5;66;03m# 注意：这里用的是训练集的距离矩阵\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 进行预测，这里我们需要提供测试集和训练集之间的距离矩阵\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 测试集和训练集之间的距离矩阵需要特别构造\u001b[39;00m\n\u001b[1;32m     33\u001b[0m X_test_train \u001b[38;5;241m=\u001b[39m distance_matrix[y_test\u001b[38;5;241m.\u001b[39mindex, :][:, y_train\u001b[38;5;241m.\u001b[39mindex]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:215\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX and y have incompatible shapes.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m samples, but y has \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples, y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    212\u001b[0m     )\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n_samples \u001b[38;5;241m!=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecomputed matrix must be a square matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Input is a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sample_weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m n_samples:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight and X have incompatible shapes: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;241m%\u001b[39m (sample_weight\u001b[38;5;241m.\u001b[39mshape, X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    227\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Precomputed matrix must be a square matrix. Input is a 2054x2568 matrix."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 加载数据\n",
    "# data = pd.read_csv('your_data.csv')  # 如果数据来自CSV文件\n",
    "\n",
    "# 标准化特征数据，因为距离计算对于数据尺度敏感\n",
    "scaler = StandardScaler()\n",
    "features = data[['cdr3_a_aa', 'v_a_gene', 'j_a_gene']]\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 计算特征的距离矩阵\n",
    "distance_matrix = pairwise_distances(features_scaled, metric='euclidean')\n",
    "# 目标变量\n",
    "target = data['antigen.epitope']\n",
    "\n",
    "# 划分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(distance_matrix, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用预计算核的 SVM\n",
    "svm_model = SVC(kernel='precomputed')\n",
    "\n",
    "# 训练模型\n",
    "svm_model.fit(X_train, y_train)  # 注意：这里用的是训练集的距离矩阵\n",
    "\n",
    "# 进行预测，这里我们需要提供测试集和训练集之间的距离矩阵\n",
    "# 测试集和训练集之间的距离矩阵需要特别构造\n",
    "X_test_train = distance_matrix[y_test.index, :][:, y_train.index]\n",
    "y_pred = svm_model.predict(X_test_train)\n",
    "\n",
    "# 输出模型的分类报告和准确度\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12efa27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "         AALALLLLDRLNQLE       0.00      0.00      0.00         1\n",
      "         AAVVRFQEAANKQKQ       0.00      0.00      0.00         1\n",
      "              ALDPHSGHFV       0.00      0.00      0.00         1\n",
      "               ALHGGWTTK       0.00      0.00      0.00         1\n",
      "               ALLPGLPAA       0.00      0.00      0.00         1\n",
      "               ALSPVIPHI       0.00      0.00      0.00         6\n",
      "               ALWGFFPVL       0.00      0.00      0.00         1\n",
      "               ALYGFVPVL       0.00      0.00      0.00         1\n",
      "            APFSEQEQPVLG       0.00      0.00      0.00         1\n",
      "           APRGPHGGAASGL       0.00      0.00      0.00         2\n",
      "               AVGSYVYSV       0.00      0.00      0.00         1\n",
      "               CINGVCWTV       0.00      0.00      0.00         3\n",
      "            CPSQEPMSIYVY       0.00      0.00      0.00         1\n",
      "            DATYQRTRALVR       0.00      0.00      0.00         3\n",
      "          DFHFEVFNFVPCSI       0.00      0.00      0.00         2\n",
      "           DPFRLLQNSQVFS       0.00      0.00      0.00         4\n",
      "           DPPALASTNAEVT       0.00      0.00      0.00         2\n",
      "        DRFYKTLRAEQASQEV       0.00      0.00      0.00         1\n",
      "              EAAGIGILTV       0.00      0.00      0.00         2\n",
      "              ELAGIGILTV       0.00      0.00      0.00         1\n",
      "             EPLPQGQLTAY       0.00      0.00      0.00         7\n",
      "               FAMQMAYRF       0.00      0.00      0.00         2\n",
      "               FLIYLDVSV       0.00      0.00      0.00         1\n",
      "               FLRGRAYGL       0.00      0.00      0.00         2\n",
      "               FLYALALLL       0.00      0.00      0.00         1\n",
      "               FMPDFDLHL       0.00      0.00      0.00         2\n",
      "   FNNFTVSFWLRVPKVSASHLE       0.00      0.00      0.00         1\n",
      "    FRDYVDRFYKTLRAEQASQE       0.00      0.00      0.00        23\n",
      "              GADGVGKSAL       0.00      0.00      0.00         1\n",
      "         GDFGLATEKSRWSGS       0.00      0.00      0.00         1\n",
      "         GELIGILNAAKVPAD       0.00      0.00      0.00         1\n",
      "               GILGFVFTL       0.03      0.04      0.03        70\n",
      "               GLCTLVAML       0.00      0.00      0.00        15\n",
      "          GLIYNRMGAVTTEV       0.00      0.00      0.00         4\n",
      "           GMFNMLSTVLGVS       0.00      0.00      0.00         2\n",
      "               GPRLGVRAT       0.00      0.00      0.00         2\n",
      "       GQVELGGGNAVEVCKGS       0.00      0.00      0.00         1\n",
      "              GTSGSPIINR       0.00      0.00      0.00         1\n",
      "               GVYALIAGA       0.00      0.00      0.00         1\n",
      "         GYNSYSVSNSEKHIM       0.00      0.00      0.00         1\n",
      "               HMTEVVRHC       0.00      0.00      0.00         1\n",
      "             HPVGEADYFEY       0.00      0.00      0.00         7\n",
      "         HWFVTQRNFYEPQII       0.00      0.00      0.00         1\n",
      "               IPSINVHHY       0.00      0.00      0.00         2\n",
      "               ITDQVPFSV       0.00      0.00      0.00         1\n",
      "               IVTDFSVIK       0.00      0.00      0.00         1\n",
      "             KAFSPEVIPMF       0.00      0.00      0.00         6\n",
      "               KASEKIFYV       0.00      0.00      0.00         1\n",
      "              KLSALGINAV       0.00      0.00      0.00         1\n",
      "              KLVALGINAV       0.00      0.00      0.00         9\n",
      "              KLVAMGINAV       0.00      0.00      0.00         1\n",
      "              KRWIILGLNK       0.00      0.00      0.00         1\n",
      "              KRWIIMGLNK       0.00      0.00      0.00         1\n",
      "           LLEFYLAMPFATP       0.00      0.00      0.00         3\n",
      "                LLFGPVYV       0.00      0.00      0.00         1\n",
      "               LLFGYPVYV       0.00      0.00      0.00         1\n",
      "               LLLGIGILV       0.00      0.00      0.00         3\n",
      "               LLWNGPMAV       0.00      0.00      0.00         4\n",
      "               LMDYWQGQL       0.00      0.00      0.00         1\n",
      "           LPEPLPQGQLTAY       0.00      0.00      0.00         2\n",
      "               LPPAYTNSF       0.00      0.00      0.00         1\n",
      "        LQPFPQPELPYGSGGS       0.00      0.00      0.00         1\n",
      "               MLAKALRKV       0.00      0.00      0.00         2\n",
      "MTEYKLVVVGAVGVGKSALTIQLI       0.00      0.00      0.00         1\n",
      "         NCTFEYVSQPFLMDL       0.00      0.00      0.00         3\n",
      "                NEGVKAAW       0.00      0.00      0.00        54\n",
      "         NFSQILPDPSKPSKR       0.00      0.00      0.00         1\n",
      "               NLNCCSVPV       0.00      0.00      0.00         1\n",
      "               NLVPMVATV       0.14      0.31      0.19       106\n",
      "               NMMWFQGQL       0.00      0.00      0.00         1\n",
      "               NYNYLYRLF       0.00      0.00      0.00         1\n",
      "               PFPQPELPY       0.00      0.00      0.00         1\n",
      "         PGVLLKEFTVSGNIL       0.00      0.00      0.00         2\n",
      "           PKYVKQNTLKLAT       0.00      0.00      0.00         5\n",
      "         PPQIAANRSQLISLV       0.00      0.00      0.00         1\n",
      "             PQPELPYPQPE       0.00      0.00      0.00         3\n",
      "           PQQPFPQPEQPFP       0.00      0.00      0.00         1\n",
      "               PTDNYITTY       0.00      0.00      0.00         1\n",
      "        QARQMVQAMRTIGTHP       0.00      0.00      0.00         4\n",
      "            QLQPFPQPELPY       0.00      0.00      0.00         1\n",
      "              QVPLRPMTYK       0.00      0.00      0.00         2\n",
      "               QYIKWPWYI       0.00      0.00      0.00         6\n",
      "               RAQAPPPSW       0.00      0.00      0.00         1\n",
      "           RFYKTLRAEQASQ       0.00      0.00      0.00         1\n",
      "         RISNCVADYSVLYNS       0.00      0.00      0.00         3\n",
      "               RLARLALVL       0.00      0.00      0.00         2\n",
      "              RLITGRLQSL       0.00      0.00      0.00         1\n",
      "                RLPAKAPL       0.00      0.00      0.00         1\n",
      "               RLPGVLPRA       0.00      0.00      0.00         1\n",
      "               RLQSLQTYV       0.00      0.00      0.00         3\n",
      "               RPRGEVRFL       0.00      0.00      0.00         5\n",
      "          SGPLKAEIAQRLED       0.00      0.00      0.00         4\n",
      "               SLLMWITQC       0.00      0.00      0.00         2\n",
      "               SPRWYFYYL       0.00      0.00      0.00         7\n",
      "              SSCMGGMNWR       0.00      0.00      0.00         1\n",
      "         STRQALRPRADGPVG       0.00      0.00      0.00         3\n",
      "             SVCAGILSYGV       0.00      0.00      0.00         1\n",
      "         TAAQAAVVRFQEAAN       0.00      0.00      0.00         2\n",
      "                TAFTIPSI       0.00      0.00      0.00         1\n",
      "               TEDEHFEFY       0.00      0.00      0.00         1\n",
      "          TFEYVSQPFLMDLE       0.00      0.00      0.00        18\n",
      "               TLWCSPIKV       0.00      0.00      0.00         1\n",
      "               TPQDLNTML       0.00      0.00      0.00         1\n",
      "              TPRVTGGGAM       0.00      0.00      0.00         1\n",
      "               VAANIVLTV       0.00      0.00      0.00         1\n",
      "         VGGNYNYLYRLFRKS       0.00      0.00      0.00         2\n",
      "               VVMSWAPPV       0.00      0.00      0.00         1\n",
      "              VVVGAVGVGK       0.00      0.00      0.00         1\n",
      "               YLEPGPVTA       0.00      0.00      0.00         1\n",
      "               YLQPRTFLL       0.00      0.00      0.00        25\n",
      "\n",
      "                accuracy                           0.07       514\n",
      "               macro avg       0.00      0.00      0.00       514\n",
      "            weighted avg       0.03      0.07      0.04       514\n",
      "\n",
      "Accuracy: 0.07003891050583658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 计算整个数据集的距离矩阵\n",
    "distance_matrix = pairwise_distances(features_scaled, metric='euclidean')\n",
    "\n",
    "# 划分数据集\n",
    "X_indices_train, X_indices_test, y_train, y_test = train_test_split(\n",
    "    np.arange(distance_matrix.shape[0]), target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 提取训练集的距离矩阵（方阵）\n",
    "X_train = distance_matrix[np.ix_(X_indices_train, X_indices_train)]\n",
    "\n",
    "# 提取测试数据和训练数据之间的距离矩阵\n",
    "X_test = distance_matrix[np.ix_(X_indices_test, X_indices_train)]\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 使用预计算核的 SVM\n",
    "svm_model = SVC(kernel='precomputed')\n",
    "\n",
    "# 使用训练集的距离矩阵训练模型\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 使用测试集和训练集之间的距离矩阵进行预测\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3be38bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLVPMVATV               467\n",
       "GILGFVFTL               309\n",
       "NEGVKAAW                209\n",
       "FRDYVDRFYKTLRAEQASQE    139\n",
       "TFEYVSQPFLMDLE          120\n",
       "                       ... \n",
       "TPQDLNTML                 2\n",
       "GYNSYSVSNSEKHIM           2\n",
       "GAVGVGKSAL                2\n",
       "RLPAKAPL                  2\n",
       "GQVELGGGNAVEVCKGS         2\n",
       "Name: antigen.epitope, Length: 155, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 假设 data 是已经加载的 pandas DataFrame，包含 'antigen.epitope' 列\n",
    "\n",
    "# 计算 'antigen.epitope' 列中每个特征的数量\n",
    "epitope_counts = data['antigen.epitope'].value_counts()\n",
    "\n",
    "epitope_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e1fae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "epitope_counts.to_csv('1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35a6453c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>complex.id</th>\n",
       "      <th>gene</th>\n",
       "      <th>cdr3_a_aa</th>\n",
       "      <th>v_a_gene</th>\n",
       "      <th>j_a_gene</th>\n",
       "      <th>species</th>\n",
       "      <th>antigen.gene</th>\n",
       "      <th>antigen.species</th>\n",
       "      <th>vdjdb.score</th>\n",
       "      <th>count</th>\n",
       "      <th>cdr3_a_aa_encoded</th>\n",
       "      <th>v_a_gene_encoded</th>\n",
       "      <th>j_a_gene_encoded</th>\n",
       "      <th>antigen.epitope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>2453</td>\n",
       "      <td>80819</td>\n",
       "      <td>27286</td>\n",
       "      <td>TRA</td>\n",
       "      <td>881</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>KRAS</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>MTEYKLVVVGARGVGKSALTIQLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>5795</td>\n",
       "      <td>469</td>\n",
       "      <td>TRA</td>\n",
       "      <td>1247</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>NS3</td>\n",
       "      <td>HCV</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1247</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>KLVALGINAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>23649</td>\n",
       "      <td>2060</td>\n",
       "      <td>TRA</td>\n",
       "      <td>1290</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>NS3</td>\n",
       "      <td>HCV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1290</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>RAQAPPPSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>2321</td>\n",
       "      <td>80206</td>\n",
       "      <td>0</td>\n",
       "      <td>TRA</td>\n",
       "      <td>482</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>Gag</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>482</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>FRDYVDRFYKTLRAEQASQE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2044</td>\n",
       "      <td>74896</td>\n",
       "      <td>0</td>\n",
       "      <td>TRA</td>\n",
       "      <td>673</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>Gag</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>673</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>KAFSPEVIPMF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>1785</td>\n",
       "      <td>363</td>\n",
       "      <td>TRA</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>DQ2-GLIA-OMEGA1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>LQPFPQPELPYGSGGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>1785</td>\n",
       "      <td>363</td>\n",
       "      <td>TRA</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>DQ2-GLIA-OMEGA1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>LQPFPQPELPYGSGGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>1785</td>\n",
       "      <td>363</td>\n",
       "      <td>TRA</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>DQ2-GLIA-OMEGA1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>LQPFPQPELPYGSGGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>1785</td>\n",
       "      <td>363</td>\n",
       "      <td>TRA</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>DQ2-GLIA-OMEGA1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>LQPFPQPELPYGSGGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>1785</td>\n",
       "      <td>363</td>\n",
       "      <td>TRA</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>DQ2-GLIA-OMEGA1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>LQPFPQPELPYGSGGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4106 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  complex.id gene  cdr3_a_aa  v_a_gene  \\\n",
       "2453          2453       80819       27286  TRA        881         4   \n",
       "424            424        5795         469  TRA       1247        31   \n",
       "1224          1224       23649        2060  TRA       1290        31   \n",
       "2321          2321       80206           0  TRA        482        37   \n",
       "2044          2044       74896           0  TRA        673         8   \n",
       "...            ...         ...         ...  ...        ...       ...   \n",
       "235            235        1785         363  TRA       1414        33   \n",
       "235            235        1785         363  TRA       1414        33   \n",
       "235            235        1785         363  TRA       1414        33   \n",
       "235            235        1785         363  TRA       1414        33   \n",
       "235            235        1785         363  TRA       1414        33   \n",
       "\n",
       "      j_a_gene      species     antigen.gene antigen.species  vdjdb.score  \\\n",
       "2453        16  HomoSapiens             KRAS     HomoSapiens            2   \n",
       "424         34  HomoSapiens              NS3             HCV            3   \n",
       "1224        27  HomoSapiens              NS3             HCV            1   \n",
       "2321        27  HomoSapiens              Gag           HIV-1            1   \n",
       "2044        11  HomoSapiens              Gag           HIV-1            1   \n",
       "...        ...          ...              ...             ...          ...   \n",
       "235         32  HomoSapiens  DQ2-GLIA-OMEGA1    Homo sapiens            3   \n",
       "235         32  HomoSapiens  DQ2-GLIA-OMEGA1    Homo sapiens            3   \n",
       "235         32  HomoSapiens  DQ2-GLIA-OMEGA1    Homo sapiens            3   \n",
       "235         32  HomoSapiens  DQ2-GLIA-OMEGA1    Homo sapiens            3   \n",
       "235         32  HomoSapiens  DQ2-GLIA-OMEGA1    Homo sapiens            3   \n",
       "\n",
       "      count  cdr3_a_aa_encoded  v_a_gene_encoded  j_a_gene_encoded  \\\n",
       "2453      1                881                 4                16   \n",
       "424       1               1247                31                34   \n",
       "1224      1               1290                31                27   \n",
       "2321      1                482                37                27   \n",
       "2044      1                673                 8                11   \n",
       "...     ...                ...               ...               ...   \n",
       "235       1               1414                33                32   \n",
       "235       1               1414                33                32   \n",
       "235       1               1414                33                32   \n",
       "235       1               1414                33                32   \n",
       "235       1               1414                33                32   \n",
       "\n",
       "               antigen.epitope  \n",
       "2453  MTEYKLVVVGARGVGKSALTIQLI  \n",
       "424                 KLVALGINAV  \n",
       "1224                 RAQAPPPSW  \n",
       "2321      FRDYVDRFYKTLRAEQASQE  \n",
       "2044               KAFSPEVIPMF  \n",
       "...                        ...  \n",
       "235           LQPFPQPELPYGSGGS  \n",
       "235           LQPFPQPELPYGSGGS  \n",
       "235           LQPFPQPELPYGSGGS  \n",
       "235           LQPFPQPELPYGSGGS  \n",
       "235           LQPFPQPELPYGSGGS  \n",
       "\n",
       "[4106 rows x 16 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Splitting the data into features and target variable\n",
    "X = data.drop('antigen.epitope', axis=1)\n",
    "y = data['antigen.epitope']\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Concatenate our training data back together\n",
    "training_set = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Separate minority and majority classes\n",
    "minority = training_set[training_set['antigen.epitope'] == training_set['antigen.epitope'].value_counts().idxmin()]\n",
    "majority = training_set[training_set['antigen.epitope'] != training_set['antigen.epitope'].value_counts().idxmin()]\n",
    "\n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority,\n",
    "                              replace=True, # Sample with replacement\n",
    "                              n_samples=len(majority), # Match number in majority class\n",
    "                              random_state=42) # Reproducible results\n",
    "\n",
    "# Combine majority and upsampled minority\n",
    "upsampled = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "# Checking counts\n",
    "upsampled['antigen.epitope'].value_counts(), upsampled.shape\n",
    "\n",
    "upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ebf09525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "Precision: 0.20\n",
      "Recall: 0.21\n",
      "F1 Score: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Ensure all necessary variables are defined and processed correctly\n",
    "labels = data['antigen.epitope']\n",
    "features = data[['cdr3_a_aa', 'v_a_gene', 'j_a_gene']]\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Splitting the dataset into training and testing sets again\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Calculate class weights based on the training labels\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Training the Random Forest model with class weights\n",
    "rf_classifier_weighted = RandomForestClassifier(random_state=30, class_weight=weights)\n",
    "rf_classifier_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test results\n",
    "y_pred_weighted = rf_classifier_weighted.predict(X_test)\n",
    "\n",
    "# Generating and displaying the classification report\n",
    "classification_report_weighted = classification_report(y_test, y_pred_weighted)\n",
    "classification_report_weighted\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred_weighted)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(y_test, y_pred_weighted, average='macro', zero_division=0)\n",
    "print(f'Precision: {precision:.2f}')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(y_test, y_pred_weighted, average='macro', zero_division=0)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(y_test, y_pred_weighted, average='macro', zero_division=0)\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b215e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24863883847549909\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "               AAFKRSCLK       0.00      0.00      0.00         1\n",
      "               AAGIGILTV       0.00      0.00      0.00         2\n",
      "         AALALLLLDRLNQLE       0.00      0.00      0.00         1\n",
      "         AAVVRFQEAANKQKQ       0.00      0.00      0.00         1\n",
      "              ALDPHSGHFV       0.00      0.00      0.00         3\n",
      "               ALHGGWTTK       0.00      0.00      0.00         2\n",
      "               ALSPVIPHI       0.00      0.00      0.00         1\n",
      "              ALWGPDPAAA       0.00      0.00      0.00         1\n",
      "               ALYGFVPVL       0.00      0.00      0.00         1\n",
      "             APARLERRHSA       0.00      0.00      0.00         1\n",
      "            APFSEQEQPVLG       0.00      0.00      0.00         1\n",
      "           APRGPHGGAASGL       0.00      0.00      0.00         2\n",
      "               CINGVCWTV       0.00      0.00      0.00         4\n",
      "            CPSQEPMSIYVY       0.00      0.00      0.00         3\n",
      "            DATYQRTRALVR       0.00      0.00      0.00         5\n",
      "          DFHFEVFNFVPCSI       0.00      0.00      0.00         1\n",
      "           DPFRLLQNSQVFS       0.00      0.00      0.00         1\n",
      "        DRFYKTLRAEQASQEV       0.00      0.00      0.00         1\n",
      "              EAAGIGILTV       0.00      0.00      0.00         2\n",
      "              ELAGIGILTV       0.00      0.00      0.00         4\n",
      "              EMLFSHGLVK       0.00      0.00      0.00         1\n",
      "             EPLPQGQLTAY       0.00      0.00      0.00         3\n",
      "               EVLPFFLFF       0.00      0.00      0.00         1\n",
      "               FAMQMAYRF       0.00      0.00      0.00         2\n",
      "               FGDVGSTLF       0.00      0.00      0.00         1\n",
      "               FLIYLDVSV       0.00      0.00      0.00         1\n",
      "               FLRGRAYGL       0.00      0.00      0.00         7\n",
      "               FLYALALLL       0.00      0.00      0.00         1\n",
      "            FPQPEQPFPWQP       0.00      0.00      0.00         1\n",
      "    FRDYVDRFYKTLRAEQASQE       0.43      0.26      0.32        23\n",
      "              FVVPYMIYLL       0.00      0.00      0.00         1\n",
      "              GARGVGKSAL       0.00      0.00      0.00         1\n",
      "         GELIGTLNAAKVPAD       0.00      0.00      0.00         1\n",
      "               GILGFVFTL       0.35      0.81      0.49        59\n",
      "               GILGLVFTL       0.00      0.00      0.00         1\n",
      "               GLCTLVAML       0.00      0.00      0.00        15\n",
      "          GLIYNRMGAVTTEV       0.00      0.00      0.00         4\n",
      "               GLLDEDFYA       0.00      0.00      0.00         1\n",
      "           GMFNMLSTVLGVS       0.00      0.00      0.00         6\n",
      "               GPRLGVRAT       0.00      0.00      0.00         3\n",
      "         GQVELGGGNAVEVCK       0.00      0.00      0.00         1\n",
      "              GTSGSPIINR       0.00      0.00      0.00         3\n",
      "              GTSGSPIVNR       0.00      0.00      0.00         1\n",
      "               GVYALIAGA       0.00      0.00      0.00         2\n",
      "               HMTEVVRHC       0.00      0.00      0.00         2\n",
      "             HPVGEADYFEY       0.00      0.00      0.00         4\n",
      "               HRRGSRSYV       0.00      0.00      0.00         1\n",
      "         HWFVTQRNFYEPQII       0.00      0.00      0.00         1\n",
      "               ILDQVPFSV       0.00      0.00      0.00         1\n",
      "               IMDQVPFSV       0.00      0.00      0.00         1\n",
      "               IPSINVHHY       0.00      0.00      0.00         3\n",
      "               ITDQVPFSV       0.00      0.00      0.00         1\n",
      "               IVTDFSVIK       0.00      0.00      0.00         2\n",
      "             KAFSPEVIPMF       0.00      0.00      0.00         6\n",
      "               KASEKIFYV       0.00      0.00      0.00         4\n",
      "              KLFEFLVYGV       0.00      0.00      0.00         1\n",
      "              KLSALGINAV       0.00      0.00      0.00         1\n",
      "              KLVALGINAV       0.00      0.00      0.00        15\n",
      "              KLVAMGINAV       0.00      0.00      0.00         1\n",
      "              KLYGLDWAEL       0.00      0.00      0.00         2\n",
      "                KMGVTYEM       0.00      0.00      0.00         1\n",
      "               KQIYKTPPI       0.00      0.00      0.00         1\n",
      "              KRWIIMGLNK       0.00      0.00      0.00         1\n",
      "               LAMPFATPM       0.00      0.00      0.00         1\n",
      "           LLEFYLAMPFATP       0.00      0.00      0.00         3\n",
      "               LLFGYPVAV       0.00      0.00      0.00         1\n",
      "               LLFGYPVYV       0.00      0.00      0.00         3\n",
      "               LLLGIGILV       0.00      0.00      0.00         5\n",
      "               LLWNGPMAV       0.00      0.00      0.00         3\n",
      "               LLYDANYFL       0.00      0.00      0.00         1\n",
      "         LNKIVRMYSPTSILD       0.00      0.00      0.00         1\n",
      "           LPEPLPQGQLTAY       0.00      0.00      0.00         1\n",
      "           LPEPLPQGQLTGY       0.00      0.00      0.00         1\n",
      "         MHVSFVMAYPEMLAA       0.00      0.00      0.00         1\n",
      "               MLAKALRKV       0.00      0.00      0.00         1\n",
      "MTEYKLVVVGARGVGKSALTIQLI       0.00      0.00      0.00         1\n",
      "         NCTFEYVSQPFLMDL       0.00      0.00      0.00         6\n",
      "                NEGVKAAW       0.50      0.02      0.04        46\n",
      "               NLNCCSVPV       0.00      0.00      0.00         3\n",
      "               NLVPMVATV       0.21      0.90      0.34        91\n",
      "         NNSYECDIPIGAGIC       0.00      0.00      0.00         1\n",
      "               NYMPYFFTL       0.00      0.00      0.00         1\n",
      "               NYNYLYRLF       0.00      0.00      0.00         2\n",
      "               PFPQPELPY       0.00      0.00      0.00         4\n",
      "         PGVLLKEFTVSGNIL       0.00      0.00      0.00         1\n",
      "           PKYVKQNTLKLAT       0.00      0.00      0.00         7\n",
      "         PPQIAANRSQLISLV       0.00      0.00      0.00         2\n",
      "               PQPELPYPQ       0.00      0.00      0.00         1\n",
      "             PQPELPYPQPE       0.00      0.00      0.00         3\n",
      "            PQPELPYPQPQL       0.00      0.00      0.00         2\n",
      "               PTDNYITTY       0.00      0.00      0.00         1\n",
      "            QAFWIDLFETIG       0.00      0.00      0.00         1\n",
      "        QARQMVQAMRTIGTHP       0.00      0.00      0.00         5\n",
      "               QIKVRVDMV       0.00      0.00      0.00         1\n",
      "            QLQPFPQPELPY       0.00      0.00      0.00         1\n",
      "             QPQQSFPEQEA       0.00      0.00      0.00         1\n",
      "              QVPLRPMTYK       0.00      0.00      0.00         1\n",
      "               QYIKWPWYI       0.00      0.00      0.00        10\n",
      "               RAQAPPPSW       0.00      0.00      0.00         1\n",
      "           RFYKTLRAEQASQ       0.00      0.00      0.00         1\n",
      "         RISNCVADYSVLYNS       0.00      0.00      0.00         2\n",
      "               RLARLALVL       0.00      0.00      0.00         1\n",
      "              RLITGRLQSL       0.00      0.00      0.00         5\n",
      "                RLPAKAPL       0.00      0.00      0.00         1\n",
      "               RLPGVLPRA       0.00      0.00      0.00         4\n",
      "               RLQSLQTYV       0.00      0.00      0.00         3\n",
      "               RMEQVDWTV       0.00      0.00      0.00         1\n",
      "               RPRGEVRFL       0.00      0.00      0.00         4\n",
      "              RQFGPDWIVA       0.00      0.00      0.00         1\n",
      "              RYPLTFGWCF       0.00      0.00      0.00         2\n",
      "               SLLMWITQC       0.00      0.00      0.00         2\n",
      "               SLLMWITQV       0.00      0.00      0.00         1\n",
      "               SLSKILDTV       0.00      0.00      0.00         1\n",
      "               SLYNTIATL       0.00      0.00      0.00         1\n",
      "                SMGVTYEM       0.00      0.00      0.00         1\n",
      "               SPRWYFYYL       0.00      0.00      0.00         4\n",
      "              SSCMGGMNWR       0.00      0.00      0.00         2\n",
      "         STRQALRPRADGPVG       0.00      0.00      0.00         1\n",
      "             SVCAGILSYGV       0.00      0.00      0.00         1\n",
      "         TAAQAAVVRFQEAAN       0.00      0.00      0.00         2\n",
      "                TAFTIPSI       0.00      0.00      0.00         7\n",
      "          TFEYVSQPFLMDLE       0.00      0.00      0.00        19\n",
      "               TLWCSPIKV       0.00      0.00      0.00         3\n",
      "               TLYSLTLLY       0.00      0.00      0.00         1\n",
      "              TPRVTGGGAM       0.00      0.00      0.00         1\n",
      "               VAANIVLTV       0.00      0.00      0.00         3\n",
      "         VGGNYNYLYRLFRKS       0.00      0.00      0.00         2\n",
      "               VMAPRTLVL       0.00      0.00      0.00         1\n",
      "                VQIISCQY       0.00      0.00      0.00         1\n",
      "               VVMSWAPPV       0.00      0.00      0.00         1\n",
      "              VVVGADGVGK       0.00      0.00      0.00         1\n",
      "              VVVGAVGVGK       0.00      0.00      0.00         2\n",
      "             WLIRETQPITK       0.00      0.00      0.00         2\n",
      "                 YHSIEWA       0.00      0.00      0.00         1\n",
      "              YLGGPDFPTI       0.00      0.00      0.00         1\n",
      "               YLQPRTFLL       0.00      0.00      0.00        18\n",
      "               YLSNIIPAL       0.00      0.00      0.00         1\n",
      "                YMGVSYEM       0.00      0.00      0.00         1\n",
      "              YPDKVFRSSV       0.00      0.00      0.00         1\n",
      "               YVLDHLIVV       0.00      0.00      0.00         1\n",
      "\n",
      "                accuracy                           0.25       551\n",
      "               macro avg       0.01      0.01      0.01       551\n",
      "            weighted avg       0.13      0.25      0.12       551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "labels = data['antigen.epitope']\n",
    "sequences = data['cdr3_a_aa']\n",
    "\n",
    "# 3. 特征提取函数：计算序列中每个字符的频率\n",
    "def feature_extraction(sequences):\n",
    "    features = []\n",
    "    for sequence in sequences:\n",
    "        # 计算序列中每个字符的频率\n",
    "        freqs = Counter(sequence)\n",
    "        # 标准化频率（可选）\n",
    "        total = sum(freqs.values())\n",
    "        features.append({char: count / total for char, count in freqs.items()})\n",
    "    return pd.DataFrame(features).fillna(0)\n",
    "\n",
    "# 应用特征提取\n",
    "features_encoded = feature_extraction(sequences)\n",
    "\n",
    "# 4. 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. 训练逻辑回归模型\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7. 评估模型\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e46fb9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         6\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.50      0.50      0.50         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.50      0.50      0.50         2\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.50      0.50      0.50         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.50      1.00      0.67         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.50      0.86      0.63         7\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.50      0.50      0.50         2\n",
      "          29       0.00      0.00      0.00         1\n",
      "          34       0.40      1.00      0.57         2\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.44      0.91      0.59        23\n",
      "          40       0.33      1.00      0.50         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.67      0.80      0.73        70\n",
      "          47       0.48      0.80      0.60        15\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.43      0.60         7\n",
      "          58       0.00      0.00      0.00         1\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.55      1.00      0.71         6\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.88      0.78      0.82         9\n",
      "          70       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.33      1.00      0.50         1\n",
      "          76       0.00      0.00      0.00         3\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       1.00      0.67      0.80         3\n",
      "          80       0.50      0.25      0.33         4\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       1.00      0.50      0.67         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.60      1.00      0.75         3\n",
      "          94       0.67      0.87      0.76        54\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.74      0.71      0.72       106\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         5\n",
      "         104       1.00      1.00      1.00         1\n",
      "         105       0.00      0.00      0.00         0\n",
      "         106       0.00      0.00      0.00         3\n",
      "         108       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       1.00      0.25      0.40         4\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         2\n",
      "         115       0.00      0.00      0.00         6\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         3\n",
      "         120       0.67      1.00      0.80         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         3\n",
      "         127       0.40      0.40      0.40         5\n",
      "         129       0.00      0.00      0.00         4\n",
      "         130       1.00      1.00      1.00         2\n",
      "         133       0.00      0.00      0.00         7\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       1.00      0.67      0.80         3\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       1.00      1.00      1.00         1\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.95      1.00      0.97        18\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         2\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.75      0.36      0.49        25\n",
      "\n",
      "    accuracy                           0.58       514\n",
      "   macro avg       0.22      0.24      0.22       514\n",
      "weighted avg       0.54      0.58      0.54       514\n",
      "\n",
      "Accuracy: 0.5836575875486382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 创建 OneHotEncoder，对序列和基因名称进行独热编码\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('cdr3_a_aa_ohe', OneHotEncoder(), ['cdr3_a_aa']),\n",
    "    ('v_a_gene_ohe', OneHotEncoder(), ['v_a_gene']),\n",
    "    ('j_a_gene_ohe', OneHotEncoder(), ['j_a_gene']),\n",
    "    ('vdjdb.score_ohe', OneHotEncoder(), ['vdjdb.score'])\n",
    "], remainder='drop')  # drop 表示除了指定的列以外的其他列将被丢弃\n",
    "\n",
    "# 对特征进行独热编码转换\n",
    "X_encoded = column_transformer.fit_transform(data_filtered)\n",
    "\n",
    "# 标签也需要转换为数值型\n",
    "y_encoded = LabelEncoder().fit_transform(data_filtered['antigen.epitope'])\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建并训练模型，这里我们仍然使用 KNN，但你也可以尝试其他模型\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# 输出模型表现\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78c73613",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 5. 训练逻辑回归模型\u001b[39;00m\n\u001b[1;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# 6. 进行预测\u001b[39;00m\n\u001b[1;32m     35\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1207\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1199\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m   1201\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1202\u001b[0m     X,\n\u001b[1;32m   1203\u001b[0m     y,\n\u001b[1;32m   1204\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1205\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[1;32m   1206\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 1207\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1208\u001b[0m )\n\u001b[1;32m   1209\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m    X : {array-like, sparse matrix, dataframe} of shape \\\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m            (n_samples, n_features), default='no validation'\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m        The input samples.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m        If `'no_validation'`, no validation is performed on `X`. This is\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m        useful for meta-estimator which can delegate input validation to\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m        their underlying estimator(s). In that case `y` must be passed and\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m        the only accepted `check_params` are `multi_output` and\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m        `y_numeric`.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    y : array-like of shape (n_samples,), default='no_validation'\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m        The targets.\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m        - If `None`, `check_array` is called on `X`. If the estimator's\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m          requires_y tag is True, then an error will be raised.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m        - If `'no_validation'`, `check_array` is called on `X` and the\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03m          estimator's requires_y tag is ignored. This is a default\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m          placeholder and is never meant to be explicitly set. In that case\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m          `X` must be passed.\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        - Otherwise, only `y` with `_check_y` or both `X` and `y` are\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m          checked with either `check_array` or `check_X_y` depending on\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m          `validate_separately`.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    reset : bool, default=True\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m        Whether to reset the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m        If False, the input will be checked for consistency with data\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m        provided when reset was last True.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m        .. note::\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m           It is recommended to call reset=True in `fit` and in the first\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m           call to `partial_fit`. All other methods that validate `X`\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;124;03m           should set `reset=False`.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m    validate_separately : False or tuple of dicts, default=False\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m        Only used if y is not None.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m        If False, call validate_X_y(). Else, it must be a tuple of kwargs\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m        to be used for calling check_array() on X and y respectively.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \n\u001b[1;32m    586\u001b[0m \u001b[38;5;124;03m        `estimator=self` is automatically added to these dicts to generate\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m        more informative error message in case of invalid input data.\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m    cast_to_ndarray : bool, default=True\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m        Cast `X` and `y` to ndarray with checks in `check_params`. If\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m        `False`, `X` and `y` are unchanged and only `feature_names_in_` and\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m        `n_features_in_` are checked.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m    **check_params : kwargs\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m        Parameters passed to :func:`sklearn.utils.check_array` or\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m        :func:`sklearn.utils.check_X_y`. Ignored if validate_separately\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m        is not False.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m        `estimator=self` is automatically added to these params to generate\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m        more informative error message in case of invalid input data.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m    out : {ndarray, sparse matrix} or tuple of these\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m        The validated input. A tuple is returned if both `X` and `y` are\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:440\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# Skip this check if the expected number of expected input features\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# was not recorded by calling fit first. This is typically the case\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# for stateless transformers.\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2021\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_monotonic_cst\u001b[39m(estimator, monotonic_cst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2006\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the monotonic constraints and return the corresponding array.\u001b[39;00m\n\u001b[1;32m   2007\u001b[0m \n\u001b[1;32m   2008\u001b[0m \u001b[38;5;124;03m    This helper function should be used in the `fit` method of an estimator\u001b[39;00m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;124;03m    that supports monotonic constraints and called after the estimator has\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;124;03m    introspected input data to set the `n_features_in_` and optionally the\u001b[39;00m\n\u001b[1;32m   2011\u001b[0m \u001b[38;5;124;03m    `feature_names_in_` attributes.\u001b[39;00m\n\u001b[1;32m   2012\u001b[0m \n\u001b[1;32m   2013\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.2\u001b[39;00m\n\u001b[1;32m   2014\u001b[0m \n\u001b[1;32m   2015\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;124;03m    estimator : estimator instance\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m \n\u001b[1;32m   2019\u001b[0m \u001b[38;5;124;03m    monotonic_cst : array-like of int, dict of str or None, default=None\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;124;03m        Monotonic constraints for the features.\u001b[39;00m\n\u001b[0;32m-> 2021\u001b[0m \n\u001b[1;32m   2022\u001b[0m \u001b[38;5;124;03m        - If array-like, then it should contain only -1, 0 or 1. Each value\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;124;03m            will be checked to be in [-1, 0, 1]. If a value is -1, then the\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;124;03m            corresponding feature is required to be monotonically decreasing.\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;124;03m        - If dict, then it the keys should be the feature names occurring in\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;124;03m            `estimator.feature_names_in_` and the values should be -1, 0 or 1.\u001b[39;00m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;124;03m        - If None, then an array of 0s will be allocated.\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m \n\u001b[1;32m   2029\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;124;03m    monotonic_cst : ndarray of int\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m \u001b[38;5;124;03m        Monotonic constraints for each feature.\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2034\u001b[0m     original_monotonic_cst \u001b[38;5;241m=\u001b[39m monotonic_cst\n\u001b[1;32m   2035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m monotonic_cst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(monotonic_cst, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "# 2. 特征提取函数：计算 `cdr3_a_aa` 中每个字符的频率\n",
    "def sequence_features(sequences):\n",
    "    features = []\n",
    "    for sequence in sequences:\n",
    "        freqs = Counter(sequence)\n",
    "        total = sum(freqs.values())\n",
    "        feature = {char: count / total for char, count in freqs.items()}\n",
    "        features.append(feature)\n",
    "    return pd.DataFrame(features).fillna(0)\n",
    "\n",
    "# 应用特征提取\n",
    "X_train_seq = sequence_features(data['cdr3_a_aa'])\n",
    "X_test_seq = sequence_features(data['cdr3_a_aa'])\n",
    "\n",
    "# 3. 独热编码 `v_a_gene` 和 `j_a_gene`\n",
    "column_trans = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(), ['v_a_gene', 'j_a_gene'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_encoded = column_trans.fit_transform(data[['v_a_gene', 'j_a_gene']])\n",
    "X_test_encoded = column_trans.transform(data[['v_a_gene', 'j_a_gene']])\n",
    "\n",
    "# 4. 合并所有特征\n",
    "X_train = pd.concat([X_train_seq.reset_index(drop=True), pd.DataFrame(X_train_encoded.toarray())], axis=1)\n",
    "X_test = pd.concat([X_test_seq.reset_index(drop=True), pd.DataFrame(X_test_encoded.toarray())], axis=1)\n",
    "y_train = data['antigen.epitope']\n",
    "y_test = data['antigen.epitope']\n",
    "\n",
    "# 5. 训练逻辑回归模型\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7. 评估模型\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a2dd3d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41379310344827586\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "               AAFKRSCLK       0.00      0.00      0.00         1\n",
      "               AAGIGILTV       0.00      0.00      0.00         2\n",
      "         AALALLLLDRLNQLE       0.00      0.00      0.00         1\n",
      "         AAVVRFQEAANKQKQ       0.00      0.00      0.00         1\n",
      "              ALDPHSGHFV       0.00      0.00      0.00         3\n",
      "               ALHGGWTTK       0.00      0.00      0.00         2\n",
      "               ALSPVIPHI       0.00      0.00      0.00         1\n",
      "              ALWGPDPAAA       0.00      0.00      0.00         1\n",
      "               ALYGFVPVL       0.00      0.00      0.00         1\n",
      "             APARLERRHSA       0.00      0.00      0.00         1\n",
      "            APFSEQEQPVLG       0.00      0.00      0.00         1\n",
      "           APRGPHGGAASGL       0.00      0.00      0.00         2\n",
      "               CINGVCWTV       0.00      0.00      0.00         4\n",
      "            CPSQEPMSIYVY       1.00      1.00      1.00         3\n",
      "            DATYQRTRALVR       0.00      0.00      0.00         5\n",
      "          DFHFEVFNFVPCSI       1.00      1.00      1.00         1\n",
      "           DPFRLLQNSQVFS       0.00      0.00      0.00         1\n",
      "        DRFYKTLRAEQASQEV       0.00      0.00      0.00         1\n",
      "              EAAGIGILTV       0.50      0.50      0.50         2\n",
      "              ELAGIGILTV       0.23      0.75      0.35         4\n",
      "              EMLFSHGLVK       0.00      0.00      0.00         1\n",
      "             EPLPQGQLTAY       1.00      0.67      0.80         3\n",
      "               EVLPFFLFF       0.00      0.00      0.00         1\n",
      "               FAMQMAYRF       0.00      0.00      0.00         2\n",
      "               FGDVGSTLF       0.00      0.00      0.00         1\n",
      "               FLIYLDVSV       0.00      0.00      0.00         1\n",
      "               FLRGRAYGL       0.00      0.00      0.00         7\n",
      "               FLYALALLL       0.00      0.00      0.00         1\n",
      "            FPQPEQPFPWQP       0.00      0.00      0.00         1\n",
      "    FRDYVDRFYKTLRAEQASQE       0.71      0.65      0.68        23\n",
      "              FVVPYMIYLL       0.00      0.00      0.00         1\n",
      "              GARGVGKSAL       0.00      0.00      0.00         1\n",
      "         GELIGTLNAAKVPAD       0.00      0.00      0.00         1\n",
      "               GILGFVFTL       0.63      0.88      0.74        59\n",
      "               GILGLVFTL       0.00      0.00      0.00         1\n",
      "               GLCTLVAML       0.62      0.67      0.65        15\n",
      "          GLIYNRMGAVTTEV       0.00      0.00      0.00         4\n",
      "               GLLDEDFYA       0.00      0.00      0.00         1\n",
      "           GMFNMLSTVLGVS       1.00      0.33      0.50         6\n",
      "               GPRLGVRAT       0.00      0.00      0.00         3\n",
      "         GQVELGGGNAVEVCK       0.00      0.00      0.00         1\n",
      "              GTSGSPIINR       0.00      0.00      0.00         3\n",
      "              GTSGSPIVNR       0.00      0.00      0.00         1\n",
      "               GVYALIAGA       0.00      0.00      0.00         2\n",
      "               HMTEVVRHC       0.00      0.00      0.00         2\n",
      "             HPVGEADYFEY       0.00      0.00      0.00         4\n",
      "               HRRGSRSYV       0.00      0.00      0.00         1\n",
      "         HWFVTQRNFYEPQII       0.00      0.00      0.00         1\n",
      "               ILDQVPFSV       0.00      0.00      0.00         1\n",
      "               IMDQVPFSV       0.00      0.00      0.00         1\n",
      "               IPSINVHHY       1.00      1.00      1.00         3\n",
      "               ITDQVPFSV       0.00      0.00      0.00         1\n",
      "               IVTDFSVIK       0.00      0.00      0.00         2\n",
      "             KAFSPEVIPMF       0.75      0.50      0.60         6\n",
      "               KASEKIFYV       0.00      0.00      0.00         4\n",
      "              KLFEFLVYGV       0.00      0.00      0.00         1\n",
      "              KLSALGINAV       0.00      0.00      0.00         1\n",
      "              KLVALGINAV       0.33      0.27      0.30        15\n",
      "              KLVAMGINAV       0.00      0.00      0.00         1\n",
      "              KLYGLDWAEL       0.00      0.00      0.00         2\n",
      "                KMGVTYEM       0.00      0.00      0.00         1\n",
      "               KQIYKTPPI       0.00      0.00      0.00         1\n",
      "              KRWIIMGLNK       0.00      0.00      0.00         1\n",
      "               LAMPFATPM       0.00      0.00      0.00         1\n",
      "           LLEFYLAMPFATP       0.00      0.00      0.00         3\n",
      "               LLFGYPVAV       0.00      0.00      0.00         1\n",
      "               LLFGYPVYV       0.00      0.00      0.00         3\n",
      "               LLLGIGILV       0.00      0.00      0.00         5\n",
      "               LLWNGPMAV       0.33      0.67      0.44         3\n",
      "               LLYDANYFL       0.00      0.00      0.00         1\n",
      "         LNKIVRMYSPTSILD       0.00      0.00      0.00         1\n",
      "           LPEPLPQGQLTAY       0.50      1.00      0.67         1\n",
      "           LPEPLPQGQLTGY       0.00      0.00      0.00         1\n",
      "         MHVSFVMAYPEMLAA       0.00      0.00      0.00         1\n",
      "               MLAKALRKV       0.00      0.00      0.00         1\n",
      "MTEYKLVVVGARGVGKSALTIQLI       0.00      0.00      0.00         1\n",
      "         NCTFEYVSQPFLMDL       0.00      0.00      0.00         6\n",
      "                NEGVKAAW       0.34      0.63      0.44        46\n",
      "               NLNCCSVPV       0.00      0.00      0.00         3\n",
      "               NLVPMVATV       0.29      0.67      0.40        91\n",
      "         NNSYECDIPIGAGIC       0.00      0.00      0.00         1\n",
      "               NYMPYFFTL       0.00      0.00      0.00         1\n",
      "               NYNYLYRLF       0.00      0.00      0.00         2\n",
      "               PFPQPELPY       0.00      0.00      0.00         4\n",
      "         PGVLLKEFTVSGNIL       0.00      0.00      0.00         1\n",
      "           PKYVKQNTLKLAT       0.00      0.00      0.00         7\n",
      "         PPQIAANRSQLISLV       0.00      0.00      0.00         2\n",
      "               PQPELPYPQ       0.00      0.00      0.00         1\n",
      "             PQPELPYPQPE       0.00      0.00      0.00         3\n",
      "            PQPELPYPQPQL       0.00      0.00      0.00         2\n",
      "               PTDNYITTY       0.00      0.00      0.00         1\n",
      "            QAFWIDLFETIG       0.00      0.00      0.00         1\n",
      "        QARQMVQAMRTIGTHP       0.67      0.80      0.73         5\n",
      "               QIKVRVDMV       0.00      0.00      0.00         1\n",
      "            QLQPFPQPELPY       0.00      0.00      0.00         1\n",
      "             QPQQSFPEQEA       0.00      0.00      0.00         1\n",
      "              QVPLRPMTYK       0.00      0.00      0.00         1\n",
      "               QYIKWPWYI       0.33      0.10      0.15        10\n",
      "               RAQAPPPSW       0.00      0.00      0.00         1\n",
      "           RFYKTLRAEQASQ       0.00      0.00      0.00         1\n",
      "         RISNCVADYSVLYNS       0.00      0.00      0.00         2\n",
      "               RLARLALVL       0.00      0.00      0.00         1\n",
      "              RLITGRLQSL       0.00      0.00      0.00         5\n",
      "                RLPAKAPL       0.00      0.00      0.00         1\n",
      "               RLPGVLPRA       0.00      0.00      0.00         4\n",
      "               RLQSLQTYV       0.00      0.00      0.00         3\n",
      "               RMEQVDWTV       0.00      0.00      0.00         1\n",
      "               RPRGEVRFL       0.00      0.00      0.00         4\n",
      "              RQFGPDWIVA       0.00      0.00      0.00         1\n",
      "              RYPLTFGWCF       0.00      0.00      0.00         2\n",
      "          SGPLKAEIAQRLED       0.00      0.00      0.00         0\n",
      "               SLLMWITQC       1.00      1.00      1.00         2\n",
      "               SLLMWITQV       0.00      0.00      0.00         1\n",
      "               SLSKILDTV       0.00      0.00      0.00         1\n",
      "               SLYNTIATL       0.00      0.00      0.00         1\n",
      "                SMGVTYEM       0.00      0.00      0.00         1\n",
      "               SPRWYFYYL       0.00      0.00      0.00         4\n",
      "              SSCMGGMNWR       0.00      0.00      0.00         2\n",
      "         STRQALRPRADGPVG       1.00      1.00      1.00         1\n",
      "             SVCAGILSYGV       0.00      0.00      0.00         1\n",
      "         TAAQAAVVRFQEAAN       0.00      0.00      0.00         2\n",
      "                TAFTIPSI       1.00      0.57      0.73         7\n",
      "          TFEYVSQPFLMDLE       0.51      1.00      0.68        19\n",
      "               TLWCSPIKV       0.00      0.00      0.00         3\n",
      "               TLYSLTLLY       0.00      0.00      0.00         1\n",
      "              TPRVTGGGAM       0.00      0.00      0.00         1\n",
      "               VAANIVLTV       0.00      0.00      0.00         3\n",
      "         VGGNYNYLYRLFRKS       0.00      0.00      0.00         2\n",
      "               VMAPRTLVL       0.00      0.00      0.00         1\n",
      "                VQIISCQY       0.00      0.00      0.00         1\n",
      "               VVMSWAPPV       0.00      0.00      0.00         1\n",
      "              VVVGADGVGK       0.00      0.00      0.00         1\n",
      "              VVVGAVGVGK       0.00      0.00      0.00         2\n",
      "             WLIRETQPITK       0.00      0.00      0.00         2\n",
      "                 YHSIEWA       0.00      0.00      0.00         1\n",
      "              YLGGPDFPTI       0.00      0.00      0.00         1\n",
      "               YLQPRTFLL       0.26      0.28      0.27        18\n",
      "               YLSNIIPAL       0.00      0.00      0.00         1\n",
      "                YMGVSYEM       0.00      0.00      0.00         1\n",
      "              YPDKVFRSSV       0.00      0.00      0.00         1\n",
      "               YVLDHLIVV       0.00      0.00      0.00         1\n",
      "\n",
      "                accuracy                           0.41       551\n",
      "               macro avg       0.11      0.11      0.10       551\n",
      "            weighted avg       0.30      0.41      0.33       551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# 2. 特征提取函数：计算 `cdr3_a_aa` 中每个字符的频率\n",
    "def sequence_features(sequences):\n",
    "    features = []\n",
    "    for sequence in sequences:\n",
    "        freqs = Counter(sequence)\n",
    "        total = sum(freqs.values())\n",
    "        feature = {char: count / total for char, count in freqs.items()}\n",
    "        features.append(feature)\n",
    "    return pd.DataFrame(features).fillna(0)\n",
    "\n",
    "# 应用特征提取\n",
    "X_seq = sequence_features(data['cdr3_a_aa'])\n",
    "\n",
    "# 3. 独热编码 `v_a_gene` 和 `j_a_gene`\n",
    "column_trans = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(), ['v_a_gene', 'j_a_gene'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_encoded = column_trans.fit_transform(data[['v_a_gene', 'j_a_gene']])\n",
    "\n",
    "# 4. 合并所有特征\n",
    "X = pd.concat([X_seq.reset_index(drop=True), pd.DataFrame(X_encoded.toarray())], axis=1)\n",
    "X.columns = X.columns.astype(str)  # 将所有列名转换为字符串类型\n",
    "y = data['antigen.epitope']\n",
    "\n",
    "# 5. 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. 训练逻辑回归模型\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 8. 评估模型\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b4ce6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25226860254083483\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "               AAFKRSCLK       0.00      0.00      0.00         1\n",
      "               AAGIGILTV       0.00      0.00      0.00         2\n",
      "         AALALLLLDRLNQLE       0.00      0.00      0.00         1\n",
      "         AAVVRFQEAANKQKQ       0.00      0.00      0.00         1\n",
      "              ALDPHSGHFV       0.00      0.00      0.00         3\n",
      "               ALHGGWTTK       0.00      0.00      0.00         2\n",
      "               ALSPVIPHI       0.00      0.00      0.00         1\n",
      "              ALWGPDPAAA       0.00      0.00      0.00         1\n",
      "               ALYGFVPVL       0.00      0.00      0.00         1\n",
      "             APARLERRHSA       0.00      0.00      0.00         1\n",
      "            APFSEQEQPVLG       0.00      0.00      0.00         1\n",
      "           APRGPHGGAASGL       0.00      0.00      0.00         2\n",
      "               CINGVCWTV       0.00      0.00      0.00         4\n",
      "            CPSQEPMSIYVY       0.00      0.00      0.00         3\n",
      "            DATYQRTRALVR       0.00      0.00      0.00         5\n",
      "          DFHFEVFNFVPCSI       0.00      0.00      0.00         1\n",
      "           DPFRLLQNSQVFS       0.00      0.00      0.00         1\n",
      "        DRFYKTLRAEQASQEV       0.00      0.00      0.00         1\n",
      "              EAAGIGILTV       0.00      0.00      0.00         2\n",
      "              ELAGIGILTV       0.00      0.00      0.00         4\n",
      "              EMLFSHGLVK       0.00      0.00      0.00         1\n",
      "             EPLPQGQLTAY       0.25      0.67      0.36         3\n",
      "               EVLPFFLFF       0.00      0.00      0.00         1\n",
      "               FAMQMAYRF       0.00      0.00      0.00         2\n",
      "               FGDVGSTLF       0.00      0.00      0.00         1\n",
      "               FLIYLDVSV       0.00      0.00      0.00         1\n",
      "               FLRGRAYGL       0.00      0.00      0.00         7\n",
      "               FLYALALLL       0.00      0.00      0.00         1\n",
      "            FPQPEQPFPWQP       0.00      0.00      0.00         1\n",
      "    FRDYVDRFYKTLRAEQASQE       0.18      0.26      0.21        23\n",
      "              FVVPYMIYLL       0.00      0.00      0.00         1\n",
      "              GARGVGKSAL       0.00      0.00      0.00         1\n",
      "         GELIGTLNAAKVPAD       0.00      0.00      0.00         1\n",
      "               GILGFVFTL       0.36      0.75      0.49        59\n",
      "               GILGLVFTL       0.00      0.00      0.00         1\n",
      "               GLCTLVAML       0.25      0.60      0.35        15\n",
      "          GLIYNRMGAVTTEV       0.00      0.00      0.00         4\n",
      "               GLLDEDFYA       0.00      0.00      0.00         1\n",
      "           GMFNMLSTVLGVS       0.00      0.00      0.00         6\n",
      "               GPRLGVRAT       0.00      0.00      0.00         3\n",
      "         GQVELGGGNAVEVCK       0.00      0.00      0.00         1\n",
      "              GTSGSPIINR       0.00      0.00      0.00         3\n",
      "              GTSGSPIVNR       0.00      0.00      0.00         1\n",
      "               GVYALIAGA       0.00      0.00      0.00         2\n",
      "               HMTEVVRHC       0.00      0.00      0.00         2\n",
      "             HPVGEADYFEY       0.00      0.00      0.00         4\n",
      "               HRRGSRSYV       0.00      0.00      0.00         1\n",
      "         HWFVTQRNFYEPQII       0.00      0.00      0.00         1\n",
      "               ILDQVPFSV       0.00      0.00      0.00         1\n",
      "               IMDQVPFSV       0.00      0.00      0.00         1\n",
      "               IPSINVHHY       0.00      0.00      0.00         3\n",
      "               ITDQVPFSV       0.00      0.00      0.00         1\n",
      "               IVTDFSVIK       0.00      0.00      0.00         2\n",
      "             KAFSPEVIPMF       0.00      0.00      0.00         6\n",
      "               KASEKIFYV       0.00      0.00      0.00         4\n",
      "              KLFEFLVYGV       0.00      0.00      0.00         1\n",
      "              KLSALGINAV       0.00      0.00      0.00         1\n",
      "              KLVALGINAV       0.00      0.00      0.00        15\n",
      "              KLVAMGINAV       0.00      0.00      0.00         1\n",
      "              KLYGLDWAEL       0.00      0.00      0.00         2\n",
      "                KMGVTYEM       0.00      0.00      0.00         1\n",
      "               KQIYKTPPI       0.00      0.00      0.00         1\n",
      "              KRWIIMGLNK       0.00      0.00      0.00         1\n",
      "               LAMPFATPM       0.00      0.00      0.00         1\n",
      "           LLEFYLAMPFATP       0.00      0.00      0.00         3\n",
      "               LLFGYPVAV       0.00      0.00      0.00         1\n",
      "               LLFGYPVYV       0.00      0.00      0.00         3\n",
      "               LLLGIGILV       0.00      0.00      0.00         5\n",
      "               LLWNGPMAV       0.00      0.00      0.00         3\n",
      "               LLYDANYFL       0.00      0.00      0.00         1\n",
      "         LNKIVRMYSPTSILD       0.00      0.00      0.00         1\n",
      "           LPEPLPQGQLTAY       0.00      0.00      0.00         1\n",
      "           LPEPLPQGQLTGY       0.00      0.00      0.00         1\n",
      "         MHVSFVMAYPEMLAA       0.00      0.00      0.00         1\n",
      "               MLAKALRKV       0.00      0.00      0.00         1\n",
      "MTEYKLVVVGARGVGKSALTIQLI       0.00      0.00      0.00         1\n",
      "         NCTFEYVSQPFLMDL       0.00      0.00      0.00         6\n",
      "                NEGVKAAW       0.50      0.02      0.04        46\n",
      "               NLNCCSVPV       0.00      0.00      0.00         3\n",
      "               NLVPMVATV       0.22      0.82      0.35        91\n",
      "         NNSYECDIPIGAGIC       0.00      0.00      0.00         1\n",
      "               NYMPYFFTL       0.00      0.00      0.00         1\n",
      "               NYNYLYRLF       0.00      0.00      0.00         2\n",
      "               PFPQPELPY       0.00      0.00      0.00         4\n",
      "         PGVLLKEFTVSGNIL       0.00      0.00      0.00         1\n",
      "           PKYVKQNTLKLAT       0.00      0.00      0.00         7\n",
      "         PPQIAANRSQLISLV       0.00      0.00      0.00         2\n",
      "               PQPELPYPQ       0.00      0.00      0.00         1\n",
      "             PQPELPYPQPE       0.00      0.00      0.00         3\n",
      "            PQPELPYPQPQL       0.00      0.00      0.00         2\n",
      "               PTDNYITTY       0.00      0.00      0.00         1\n",
      "            QAFWIDLFETIG       0.00      0.00      0.00         1\n",
      "        QARQMVQAMRTIGTHP       0.00      0.00      0.00         5\n",
      "               QIKVRVDMV       0.00      0.00      0.00         1\n",
      "            QLQPFPQPELPY       0.00      0.00      0.00         1\n",
      "             QPQQSFPEQEA       0.00      0.00      0.00         1\n",
      "              QVPLRPMTYK       0.00      0.00      0.00         1\n",
      "               QYIKWPWYI       0.00      0.00      0.00        10\n",
      "               RAQAPPPSW       0.00      0.00      0.00         1\n",
      "           RFYKTLRAEQASQ       0.00      0.00      0.00         1\n",
      "         RISNCVADYSVLYNS       0.00      0.00      0.00         2\n",
      "               RLARLALVL       0.00      0.00      0.00         1\n",
      "              RLITGRLQSL       0.00      0.00      0.00         5\n",
      "                RLPAKAPL       0.00      0.00      0.00         1\n",
      "               RLPGVLPRA       0.00      0.00      0.00         4\n",
      "               RLQSLQTYV       0.00      0.00      0.00         3\n",
      "               RMEQVDWTV       0.00      0.00      0.00         1\n",
      "               RPRGEVRFL       0.00      0.00      0.00         4\n",
      "              RQFGPDWIVA       0.00      0.00      0.00         1\n",
      "              RYPLTFGWCF       0.00      0.00      0.00         2\n",
      "               SLLMWITQC       0.00      0.00      0.00         2\n",
      "               SLLMWITQV       0.00      0.00      0.00         1\n",
      "               SLSKILDTV       0.00      0.00      0.00         1\n",
      "               SLYNTIATL       0.00      0.00      0.00         1\n",
      "                SMGVTYEM       0.00      0.00      0.00         1\n",
      "               SPRWYFYYL       0.00      0.00      0.00         4\n",
      "              SSCMGGMNWR       0.00      0.00      0.00         2\n",
      "         STRQALRPRADGPVG       1.00      1.00      1.00         1\n",
      "             SVCAGILSYGV       0.00      0.00      0.00         1\n",
      "         TAAQAAVVRFQEAAN       0.00      0.00      0.00         2\n",
      "                TAFTIPSI       0.00      0.00      0.00         7\n",
      "          TFEYVSQPFLMDLE       0.00      0.00      0.00        19\n",
      "               TLWCSPIKV       0.00      0.00      0.00         3\n",
      "               TLYSLTLLY       0.00      0.00      0.00         1\n",
      "              TPRVTGGGAM       0.00      0.00      0.00         1\n",
      "               VAANIVLTV       0.00      0.00      0.00         3\n",
      "         VGGNYNYLYRLFRKS       0.00      0.00      0.00         2\n",
      "               VMAPRTLVL       0.00      0.00      0.00         1\n",
      "                VQIISCQY       0.00      0.00      0.00         1\n",
      "               VVMSWAPPV       0.00      0.00      0.00         1\n",
      "              VVVGADGVGK       0.00      0.00      0.00         1\n",
      "              VVVGAVGVGK       0.00      0.00      0.00         2\n",
      "             WLIRETQPITK       0.00      0.00      0.00         2\n",
      "                 YHSIEWA       0.00      0.00      0.00         1\n",
      "              YLGGPDFPTI       0.00      0.00      0.00         1\n",
      "               YLQPRTFLL       0.20      0.06      0.09        18\n",
      "               YLSNIIPAL       0.00      0.00      0.00         1\n",
      "                YMGVSYEM       0.00      0.00      0.00         1\n",
      "              YPDKVFRSSV       0.00      0.00      0.00         1\n",
      "               YVLDHLIVV       0.00      0.00      0.00         1\n",
      "\n",
      "                accuracy                           0.25       551\n",
      "               macro avg       0.02      0.03      0.02       551\n",
      "            weighted avg       0.14      0.25      0.14       551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  args=(X, target, sample_weight, l2_reg_strength, n_threads),\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lulu/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# 2. 特征提取函数：计算 `cdr3_a_aa` 中每个字符的频率\n",
    "def sequence_features(sequences):\n",
    "    features = []\n",
    "    for sequence in sequences:\n",
    "        freqs = Counter(sequence)\n",
    "        total = sum(freqs.values())\n",
    "        feature = {char: count / total for char, count in freqs.items()}\n",
    "        features.append(feature)\n",
    "    return pd.DataFrame(features).fillna(0)\n",
    "\n",
    "# 应用特征提取\n",
    "X_seq = sequence_features(data['cdr3_a_aa'])\n",
    "\n",
    "# 3. 使用 LabelEncoder 转换 `v_a_gene` 和 `j_a_gene`\n",
    "label_encoder_v = LabelEncoder()\n",
    "label_encoder_j = LabelEncoder()\n",
    "\n",
    "v_encoded = label_encoder_v.fit_transform(data['v_a_gene'])\n",
    "j_encoded = label_encoder_j.fit_transform(data['j_a_gene'])\n",
    "\n",
    "# 4. 合并所有特征\n",
    "X = pd.concat([\n",
    "    X_seq.reset_index(drop=True), \n",
    "    pd.DataFrame(v_encoded, columns=['v_a_gene']),\n",
    "    pd.DataFrame(j_encoded, columns=['j_a_gene'])\n",
    "], axis=1)\n",
    "\n",
    "y = data['antigen.epitope']\n",
    "\n",
    "# 5. 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. 训练逻辑回归模型\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 8. 评估模型\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7548b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
