{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4f7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "data=pd.read_csv('./vdjdb.txt',sep='\\t', header=0)\n",
    "data[data['species'] == 'MusMusculus']\n",
    "data=data[data['vdjdb.score'] != 0]\n",
    "columns_to_drop = ['antigen.species','antigen.gene','reference.id', 'method', 'meta','cdr3fix','web.method','web.method.seq','web.cdr3fix.nc','web.cdr3fix.unmp','mhc.a','mhc.b','mhc.class']\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "data=data.dropna()\n",
    "data_alpha_Mus = data[data['gene'] == 'TRA'].copy()\n",
    "class_counts = data_alpha_Mus['antigen.epitope'].value_counts()\n",
    "single_classes = class_counts[class_counts == 1].index\n",
    "data_alpha_Mus_filtered = data_alpha_Mus[~data_alpha_Mus['antigen.epitope'].isin(single_classes)]\n",
    "y = data_alpha_Mus_filtered['antigen.epitope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d10af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(\n",
    "    [\n",
    "        ('one_hot_encoder_vj', OneHotEncoder(), ['v.segm', 'j.segm']),\n",
    "        ('one_hot_encoder_cdr3', OneHotEncoder(handle_unknown='ignore'), ['cdr3'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X_encoded = column_trans.fit_transform(data_alpha_Mus_filtered)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b617c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Precision: 0.33\n",
      "Recall: 0.33\n",
      "F1 Score: 0.30\n"
     ]
    }
   ],
   "source": [
    "# 5. 计算类别权重\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weights = dict(zip(np.unique(y_train), class_weights))\n",
    "#*\n",
    "# 6. 训练随机森林模型\n",
    "rf_classifier_weighted = RandomForestClassifier(random_state=30, class_weight=weights)\n",
    "rf_classifier_weighted.fit(X_train, y_train)\n",
    "\n",
    "# 7. 进行预测\n",
    "y_pred_weighted = rf_classifier_weighted.predict(X_test)\n",
    "\n",
    "# 8. 生成和显示分类报告\n",
    "classification_report_weighted = classification_report(y_test, y_pred_weighted, zero_division=0)\n",
    "#print(classification_report_weighted)\n",
    "\n",
    "# 9. 计算和显示准确率、精确度、召回率和F1分数\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(y_test, y_pred_weighted)\n",
    "precision = precision_score(y_test, y_pred_weighted, average='macro', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred_weighted, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_weighted, average='macro', zero_division=0)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "#onehot编码，随机森林预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c434d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Actual       Predicted\n",
      "69352   SSPPMFRV        SSPPMFRV\n",
      "24488  QYIKWPWYI       NLVPMVATV\n",
      "6206   NLVPMVATV       NLVPMVATV\n",
      "24436  QYIKWPWYI       NLVPMVATV\n",
      "4381    NEGVKAAW        NEGVKAAW\n",
      "...          ...             ...\n",
      "89647  YLQPRTFLL       YLQPRTFLL\n",
      "34144  IVTDFSVIK       IVTDFSVIK\n",
      "74243  PFPQPELPY  TFEYVSQPFLMDLE\n",
      "72964   TVYGFCLL       SSYRRPVGI\n",
      "6140   NLVPMVATV       NLVPMVATV\n",
      "\n",
      "[697 rows x 2 columns]\n",
      "Mismatched Predictions:\n",
      "          Actual       Predicted\n",
      "24488  QYIKWPWYI       NLVPMVATV\n",
      "24436  QYIKWPWYI       NLVPMVATV\n",
      "70332  SSYRRPVGI       NLVPMVATV\n",
      "68152  LSLRNPILV       NLVPMVATV\n",
      "1747   ASNENMETM       GILGFVFTL\n",
      "...          ...             ...\n",
      "72886  HGIRNASFI       ASNENMETM\n",
      "68858  SSYRRPVGI      SSLENFRAYV\n",
      "69332  HGIRNASFI       SSYRRPVGI\n",
      "74243  PFPQPELPY  TFEYVSQPFLMDLE\n",
      "72964   TVYGFCLL       SSYRRPVGI\n",
      "\n",
      "[298 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_weighted})\n",
    "print(results_df) \n",
    "mismatches = results_df[results_df['Actual'] != results_df['Predicted']]\n",
    "print(\"Mismatched Predictions:\")\n",
    "print(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744aa4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Counts by Actual Category:\n",
      "NLVPMVATV        19\n",
      "GILGFVFTL        16\n",
      "SSYRRPVGI        11\n",
      "SSPPMFRV         10\n",
      "HGIRNASFI         9\n",
      "                 ..\n",
      "GMFNMLSTVLGVS     1\n",
      "VQIISCQY          1\n",
      "EAAGIGILTV        1\n",
      "QLSPFPFDL         1\n",
      "LLWNGPMAV         1\n",
      "Name: Actual, Length: 99, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "error_counts = mismatches['Actual'].value_counts()\n",
    "print(\"Error Counts by Actual Category:\")\n",
    "print(error_counts)\n",
    "error_counts.to_csv(\"error_counts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
